{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c90cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DEGIS environment is active\n",
      "üêç Python: /data/degis/degis-env/bin/python\n",
      "‚úÖ DEGIS package is available\n",
      "\n",
      "üöÄ Ready to start image generation!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ENVIRONMENT CHECK - Run this cell first!\n",
    "# =============================================================================\n",
    "# This cell verifies that the DEGIS environment is properly set up\n",
    "# Make sure you've run ./setup_server_fixed.sh first!\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check if we're in the right environment\n",
    "if 'degis-env' in sys.executable:\n",
    "    print(\"‚úÖ DEGIS environment is active\")\n",
    "    print(f\"üêç Python: {sys.executable}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Warning: DEGIS environment not detected\")\n",
    "    print(\"   Please run: ./setup_server_fixed.sh\")\n",
    "    print(\"   Then activate: source degis-env/bin/activate\")\n",
    "\n",
    "# Check if DEGIS package is available\n",
    "try:\n",
    "    import degis\n",
    "    print(\"‚úÖ DEGIS package is available\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå DEGIS package not found\")\n",
    "    print(\"   Please run: ./setup_server_fixed.sh\")\n",
    "\n",
    "print(\"\\nüöÄ Ready to start image generation!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS - Run this after the setup cell above\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Import DEGIS package components\n",
    "from degis import IPAdapterXLGenerator, load_trained_color_head, get_color_embedding\n",
    "from degis.shared.utils import create_control_edge_pil, plot_color_palette, display_images_grid, display_comparison_grid\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(\"üé® Ready for high-quality image generation with IP-Adapter XL!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52def9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from IPython.display import display\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Import the DEGIS package\n",
    "from degis.data.dataset import UnifiedImageDataset\n",
    "\n",
    "# Import IP-Adapter XL with DEGIS patches\n",
    "import ip_adapter_patch  # This applies the DEGIS monkey patches\n",
    "from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline\n",
    "from degis.shared.image_features.color_histograms import compute_color_histogram, compute_lab_histogram\n",
    "from degis.shared.utils.image_utils import create_control_edge_pil\n",
    "import geomloss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61365ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/data/thesis/laion_5m_manifest.csv\"\n",
    "embeddings_path = \"/data/thesis/models/hf_xl_laion_5m_embeddings.npy\" # || YOUR_CUSTOM_PATH\n",
    "colour_path = \"/data/thesis/data/laion_5m_color_histograms_lab_514.npy\" # options: COLOR_HIST_PATH_LAB_514 || COLOR_HIST_PATH_RGB || YOUR_CUSTOM_PATH\n",
    "colour_head_checkpoint_path = \"/data/degis/evaluation_runs/laion_5m_xl_lab514_tk20_b4096/best_color_head_tmp.pth\" # || YOUR_CUSTOM_PATH\n",
    "precomputed_adimagenet_edge_maps_path = \"/data/thesis/data/adimagenet_edge_maps.npy\" # || YOUR_CUSTOM_PATH\n",
    "\n",
    "\n",
    "# ip_ckpt = \"/data/thesis/models/ip-adapter_sd15.bin\"\n",
    "image_encoder_path = \"laion/CLIP-ViT-bigG-14-laion2B-39B-b160k\"\n",
    "controlnet_id = \"diffusers/controlnet-canny-sdxl-1.0\"\n",
    "# stable_diffusion_model_id = \"runwayml/stable-diffusion-v1-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from degis.inference import load_trained_color_head\n",
    "# Load datasets\n",
    "df = pd.read_csv(csv_path)\n",
    "colour_dataset = UnifiedImageDataset(\n",
    "    df.rename(columns={\"local_path\": \"file_path\"}),\n",
    "    mode=\"file_df\",\n",
    "    size=(224, 224),\n",
    "    subset_ratio=1.0\n",
    ")\n",
    "\n",
    "# Load precomputed data\n",
    "embeddings = np.load(embeddings_path, mmap_mode=\"r\").astype(np.float32, copy=False)\n",
    "histograms = np.load(colour_path, mmap_mode=\"r\").astype(np.float32, copy=False)\n",
    "edge_maps = np.load(precomputed_adimagenet_edge_maps_path, mmap_mode=\"r\")\n",
    "\n",
    "print(f\"Loaded embeddings: {embeddings.shape}\")\n",
    "print(f\"Loaded histograms: {histograms.shape}\")\n",
    "print(f\"Loaded edge maps: {edge_maps.shape}\")\n",
    "\n",
    "# Load trained color head\n",
    "color_head = load_trained_color_head(\n",
    "    checkpoint_path=colour_head_checkpoint_path,\n",
    "    clip_dim=embeddings.shape[1],\n",
    "    hist_dim=histograms.shape[1],\n",
    "    device=device\n",
    ")\n",
    "print(\"‚úì Color head loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d06a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cache directory\n",
    "HF_CACHE = \"/data/hf-cache\" if os.path.exists(\"/data\") else \"./hf-cache\"\n",
    "os.makedirs(HF_CACHE, exist_ok=True)\n",
    "\n",
    "os.environ[\"HF_HOME\"] = HF_CACHE\n",
    "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = os.path.join(HF_CACHE, \"hub\")\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = os.path.join(HF_CACHE, \"transformers\")\n",
    "os.environ[\"DIFFUSERS_CACHE\"] = os.path.join(HF_CACHE, \"diffusers\")\n",
    "os.environ[\"TORCH_HOME\"] = os.path.join(HF_CACHE, \"torch\")\n",
    "\n",
    "print(f\"Using cache directory: {HF_CACHE}\")\n",
    "\n",
    "# Create IP-Adapter XL generator\n",
    "generator = IPAdapterXLGenerator(device=device)\n",
    "\n",
    "# Setup the pipeline\n",
    "generator.setup_pipeline(\n",
    "    model_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    controlnet_id=controlnet_id,\n",
    "    ip_ckpt=None,  # Update path as needed\n",
    "    image_encoder_path=image_encoder_path,\n",
    "    cache_dir=HF_CACHE,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "print(\"‚úì IP-Adapter XL pipeline setup complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "def generate_from_dataset_id_xl(\n",
    "    colour_index: int,\n",
    "    layout_index: int,\n",
    "    prompt: str = \"a cat playing with a ball\",\n",
    "    guidance_scale: float = 6.5,\n",
    "    steps: int = 40,\n",
    "    controlnet_conditioning_scale: float = 0.8,\n",
    "    num_samples: int = 1,\n",
    "    attn_ip_scale: float = 0.8,\n",
    "    text_token_scale: float = 1.0,\n",
    "    ip_token_scale: float = None,\n",
    "    ip_uncond_scale: float = 0.0,\n",
    "    zero_ip_in_uncond: bool = True,\n",
    "):\n",
    "    \"\"\"Generate images using IP-Adapter XL with advanced controls.\"\"\"\n",
    "    import torch, gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # Get original image for display\n",
    "    img_t, _ = colour_dataset[colour_index]\n",
    "    pil_img = transforms.ToPILImage()(img_t)\n",
    "    \n",
    "    # Get CLIP embedding and compute color embedding\n",
    "    z_clip = torch.as_tensor(embeddings[colour_index], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    color_embedding = get_color_embedding(color_head, z_clip)\n",
    "    \n",
    "    # Create control image from edge data\n",
    "    control_image = create_control_edge_pil(edge_maps[layout_index], size=512)\n",
    "    \n",
    "    # Generate images with IP-Adapter XL\n",
    "    images = generator.generate(\n",
    "        color_embedding=color_embedding,\n",
    "        control_image=control_image,\n",
    "        prompt=prompt,\n",
    "        # negative_prompt=(\n",
    "        #     \"monochrome, lowres, bad anatomy, worst quality, low quality, blurry, \"\n",
    "        #     \"sketch, cartoon, drawing, anime:1.4, comic, illustration, posterized, \"\n",
    "        #     \"mosaic, stained glass, abstract, surreal, psychedelic, trippy, texture artifact, \"\n",
    "        #     \"embroidery, knitted, painting, oversaturated, unrealistic, bad shading\"\n",
    "        # ),\n",
    "        num_samples=num_samples,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_inference_steps=steps,\n",
    "        controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
    "        # IP-Adapter XL specific parameters\n",
    "        attn_ip_scale=attn_ip_scale,\n",
    "        text_token_scale=text_token_scale,\n",
    "        ip_token_scale=ip_token_scale,\n",
    "        ip_uncond_scale=ip_uncond_scale,\n",
    "        zero_ip_in_uncond=zero_ip_in_uncond,\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    comparison = display_comparison_grid(\n",
    "        original=pil_img,\n",
    "        control=control_image,\n",
    "        generated=images,\n",
    "        cols=3\n",
    "    )\n",
    "    display(comparison)\n",
    "    \n",
    "    return images\n",
    "\n",
    "print(\"‚úì IP-Adapter XL generation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34959233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==== Aligned GT vs Pred top-20 + IMAGE (first 10) ====\n",
    "# import os, numpy as np, torch, matplotlib.pyplot as plt, pandas as pd\n",
    "# from skimage.color import lab2rgb\n",
    "# BINS      = 8\n",
    "# TOP_K     = 14\n",
    "# SPACE = \"lab\"\n",
    "# hist = histograms\n",
    "# emb = embeddings\n",
    "# HIST_KIND = \"lab514\"   # \"rgb512\" | \"lab514\" | \"hcl514\"\n",
    "# sinkhorn = geomloss.SamplesLoss(\"sinkhorn\", p=2, blur=0.05, backend=\"tensorized\")\n",
    "# def _top_palette(vec, bins=BINS, top_k=TOP_K, space=SPACE, c_max=150.0):\n",
    "#     v = vec.detach().cpu().numpy() if isinstance(vec, torch.Tensor) else np.asarray(vec)\n",
    "#     core = v[:bins**3]  # ignore the last 2 BW slots for palette picking\n",
    "#     idxs = np.argsort(core)[-top_k:][::-1]\n",
    "#     cols = []\n",
    "#     if space == \"rgb\":\n",
    "#         for flat in idxs:\n",
    "#             ri = flat // (bins*bins); gi = (flat // bins) % bins; bi = flat % bins\n",
    "#             cols.append(((ri+0.5)/bins, (gi+0.5)/bins, (bi+0.5)/bins))\n",
    "#     elif space == \"lab\":\n",
    "#         for flat in idxs:\n",
    "#             Li = flat // (bins*bins); ai = (flat // bins) % bins; bi = flat % bins\n",
    "#             L = (Li+0.5)/bins*100.0\n",
    "#             a = (ai+0.5)/bins*255.0 - 128.0\n",
    "#             b = (bi+0.5)/bins*255.0 - 128.0\n",
    "#             cols.append(tuple(lab2rgb(np.array([[[L,a,b]]]))[0,0]))\n",
    "#     elif space == \"hcl\":\n",
    "#         for flat in idxs:\n",
    "#             Li = flat // (bins*bins); Ci = (flat // bins) % bins; Hi = flat % bins\n",
    "#             L = (Li+0.5)/bins*100.0\n",
    "#             C = (Ci+0.5)/bins*c_max\n",
    "#             H = (Hi+0.5)/bins*360.0\n",
    "#             a = C*np.cos(np.deg2rad(H)); b = C*np.sin(np.deg2rad(H))\n",
    "#             cols.append(tuple(lab2rgb(np.array([[[L,a,b]]]))[0,0]))\n",
    "#     else:\n",
    "#         raise ValueError(\"space must be 'rgb' | 'lab' | 'hcl'\")\n",
    "#     return cols, core[idxs]\n",
    "\n",
    "# def _plot_palette(ax, colors, values, title):\n",
    "#     for i, (c, v) in enumerate(zip(colors, values)):\n",
    "#         ax.add_patch(plt.Rectangle((i, 0), 1, 1, color=c))\n",
    "#         ax.text(i+0.5, -0.08, f\"{v:.3f}\", ha=\"center\", va=\"top\", fontsize=7)\n",
    "#     ax.set_xlim(0, len(colors)); ax.set_ylim(0,1); ax.axis(\"off\")\n",
    "#     ax.set_title(title, fontsize=12)\n",
    "\n",
    "# def show_aligned(i, dataset):\n",
    "#     # image from the SAME dataset (guarantees correct ordering)\n",
    "#     img_t, _ = dataset[i]                    # [3,224,224] float [0,1]\n",
    "#     img_np   = img_t.permute(1,2,0).numpy()  # HWC\n",
    "\n",
    "#     # GT and Pred from aligned arrays / model\n",
    "#     h_gt = torch.from_numpy(hist[i]).to(device)\n",
    "#     z    = torch.from_numpy(emb[i]).to(device).unsqueeze(0)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         _, p, _ = color_head(z)\n",
    "#         p = p.squeeze(0)\n",
    "#         p = p / (p.sum() + 1e-8)\n",
    "#         g = h_gt / (h_gt.sum() + 1e-8)\n",
    "#         l1  = torch.sum(torch.abs(p-g)).item()\n",
    "#         cos = torch.nn.functional.cosine_similarity(p, g, dim=0).item()\n",
    "#         emd = sinkhorn(p.unsqueeze(0), g.unsqueeze(0)).item() if sinkhorn is not None else None\n",
    "\n",
    "#     gt_cols, gt_vals = _top_palette(g)\n",
    "#     pr_cols, pr_vals = _top_palette(p)\n",
    "\n",
    "#     # draw\n",
    "#     fig, axes = plt.subplots(2, 2, figsize=(14, 5), gridspec_kw={\"height_ratios\":[2,1]})\n",
    "#     axes[0,0].imshow(img_np); axes[0,0].axis(\"off\")\n",
    "#     basename = os.path.basename(str(dataset.df.iloc[i][\"file_path\"]))\n",
    "#     # axes[0,0].set_title(f\"idx={i}  ({basename})\")\n",
    "#     axes[0,0].set_title(f\"EMD={emd:.4f}\")\n",
    "#     # if emd is not None: txt += f\"\\nEMD = {emd:.4f}\"\n",
    "\n",
    "#     axes[0,1].axis(\"off\")\n",
    "#     txt = f\"Histogram kind: {HIST_KIND}\\nL1 = {l1:.4f}\\nCosine = {cos:.4f}\"\n",
    "#     if emd is not None: txt += f\"\\nEMD = {emd:.4f}\"\n",
    "#     axes[0,1].text(0.02, 0.85, txt, fontsize=12, va=\"top\")\n",
    "\n",
    "#     _plot_palette(axes[1,0], pr_cols, pr_vals, f\"Pred top-bins\")\n",
    "#     _plot_palette(axes[1,1], gt_cols, gt_vals, f\"GT top-{TOP_K}\")\n",
    "#     plt.tight_layout(); plt.show()\n",
    "\n",
    "# for i in range(100000, 100020):\n",
    "#     show_aligned(i, colour_dataset)\n",
    "# # for i in range(1000, 1010):\n",
    "# #     show_aligned(i, colour_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc98587",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_from_dataset_id_xl(\n",
    "    colour_index=1008,\n",
    "    layout_index=71,\n",
    "    prompt=\"a car, reaslistic background, professional photography\",\n",
    "    guidance_scale=15,\n",
    "    steps=50,\n",
    "    controlnet_conditioning_scale=0.4,\n",
    "    num_samples=1,\n",
    "    attn_ip_scale=0.6,\n",
    "    text_token_scale=1.0,\n",
    "    ip_token_scale=0.4,\n",
    "    ip_uncond_scale=0.0,\n",
    "    zero_ip_in_uncond=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_from_dataset_id_xl(\n",
    "    colour_index=1000,\n",
    "    layout_index=71,\n",
    "    prompt=\"a car, reaslistic background, professional photography\",\n",
    "    guidance_scale=15,\n",
    "    steps=100,\n",
    "    controlnet_conditioning_scale=0.4,\n",
    "    num_samples=1,\n",
    "    attn_ip_scale=0.6,\n",
    "    text_token_scale=1.0,\n",
    "    ip_token_scale=0.4,\n",
    "    ip_uncond_scale=0.0,\n",
    "    zero_ip_in_uncond=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f69e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_from_dataset_id_xl(\n",
    "    colour_index=1000,\n",
    "    layout_index=381,\n",
    "    prompt=\"a car, no text, realistic background, professional photography\",\n",
    "    guidance_scale=15,\n",
    "    steps=100,\n",
    "    controlnet_conditioning_scale=0.4,\n",
    "    num_samples=1,\n",
    "    attn_ip_scale=0.6,\n",
    "    text_token_scale=1.0,\n",
    "    ip_token_scale=0.4,\n",
    "    ip_uncond_scale=0.0,\n",
    "    zero_ip_in_uncond=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ae190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [6, 21, 33, 45, 67, 104, 141, 177, 232, 382, 311, 438, 440, 503]:\n",
    "#     generate_from_dataset_id_xl(\n",
    "#     colour_index=1008,\n",
    "#     layout_index=i,\n",
    "#     prompt=\"identical hoodies, advertisement style, professional photography\",\n",
    "#     guidance_scale=15,\n",
    "#     steps=50,\n",
    "#     controlnet_conditioning_scale=0.4,\n",
    "#     num_samples=1,\n",
    "#     attn_ip_scale=0.6,\n",
    "#     text_token_scale=1.5,\n",
    "#     ip_token_scale=0.4,\n",
    "#     ip_uncond_scale=0.0,\n",
    "#     zero_ip_in_uncond=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba765f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca16f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c124f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".prompt {\n",
    "    display: none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c304b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63347548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "degis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
