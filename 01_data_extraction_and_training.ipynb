{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Extraction and Training with DEGIS Package\n",
        "\n",
        "This notebook demonstrates how to use the DEGIS package to:\n",
        "1. Extract CLIP embeddings from images\n",
        "2. Generate color histograms and edge maps\n",
        "3. Train color disentanglement models\n",
        "\n",
        "Based on the logic from `main.py` but using the new package structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# AUTOMATIC SETUP - Run this cell first!\n",
        "# =============================================================================\n",
        "# This cell will automatically set up the DEGIS package and dependencies\n",
        "# You only need to run this once per session\n",
        "\n",
        "from env_setup import setup_training_environment\n",
        "\n",
        "# Run the setup for training notebooks\n",
        "setup_training_environment()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# IMPORTS - Run this after the setup cell above\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Import DEGIS package components\n",
        "import degis\n",
        "from degis.core.embeddings import generate_clip_embeddings, generate_xl_embeddings\n",
        "from degis.core.features import generate_color_histograms, generate_edge_maps\n",
        "from degis.core.training import train_color_model, train_edge_model\n",
        "from degis.data.dataset import UnifiedImageDataset\n",
        "from degis.config import CSV_PATH, BATCH_SIZE, EMBEDDINGS_TARGET_PATH\n",
        "\n",
        "print(\"\u2705 All imports successful!\")\n",
        "print(f\"\ud83d\udcca Using CSV_PATH: {CSV_PATH}\")\n",
        "print(f\"\ud83d\udce6 Using BATCH_SIZE: {BATCH_SIZE}\")\n",
        "from multiprocessing import cpu_count\n",
        "import os\n",
        "import time\n",
        "import platform\n",
        "import psutil\n",
        "import shutil\n",
        "\n",
        "# Import the DEGIS package\n",
        "import degis\n",
        "from degis.data.dataset import UnifiedImageDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. System Profiling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SYSTEM PROFILE ===\n",
            "Python: 3.12.3\n",
            "PyTorch: 2.8.0+cu128\n",
            "CPU cores: 256\n",
            "RAM: 540.8 GB, free 407.9 GB\n",
            "/data disk: total 1099.5 GB, free 249.4 GB\n",
            "CUDA available: True\n",
            "GPU: NVIDIA GeForce RTX 5090\n",
            "VRAM total: 33.7 GB\n",
            "======================\n"
          ]
        }
      ],
      "source": [
        "def print_system_profile():\n",
        "    print(\"=== SYSTEM PROFILE ===\")\n",
        "    print(\"Python:\", platform.python_version())\n",
        "    print(\"PyTorch:\", torch.__version__)\n",
        "    print(\"CPU cores:\", psutil.cpu_count(logical=True))\n",
        "    vm = psutil.virtual_memory()\n",
        "    print(f\"RAM: {vm.total/1e9:.1f} GB, free {vm.available/1e9:.1f} GB\")\n",
        "    \n",
        "    # Check if /data exists, otherwise check current directory\n",
        "    if os.path.exists(\"/data\"):\n",
        "        du = shutil.disk_usage(\"/data\")\n",
        "        print(f\"/data disk: total {du.total/1e9:.1f} GB, free {du.free/1e9:.1f} GB\")\n",
        "    else:\n",
        "        du = shutil.disk_usage(\".\")\n",
        "        print(f\"Current disk: total {du.total/1e9:.1f} GB, free {du.free/1e9:.1f} GB\")\n",
        "    \n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        i = torch.cuda.current_device()\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(i))\n",
        "        print(f\"VRAM total: {torch.cuda.get_device_properties(i).total_memory/1e9:.1f} GB\")\n",
        "    print(\"======================\")\n",
        "\n",
        "print_system_profile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Dataset and Create Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "embeddings_size = \"xl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_path = \"/data/thesis/coco_manifest.csv\"\n",
        "embeddings_path = \"/data/thesis/models/hf_xl_coco_embeddings.npy\"\n",
        "colour_hist_path = \"/data/thesis/data/adimagenet_color_histograms_hcl_514.npy\" \n",
        "edge_maps_path = \"/data/thesis/data/adimagenet_edge_maps.npy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded: 616767 images\n",
            "Columns: ['split', 'image_id', 'file_name', 'local_path', 'caption']\n",
            "\n",
            "First few rows:\n",
            "   split  image_id         file_name  \\\n",
            "0  train    203564  000000203564.jpg   \n",
            "1  train    322141  000000322141.jpg   \n",
            "2  train     16977  000000016977.jpg   \n",
            "3  train    106140  000000106140.jpg   \n",
            "4  train    106140  000000106140.jpg   \n",
            "\n",
            "                                          local_path  \\\n",
            "0  /data/thesis/coco/images/train2017/00000020356...   \n",
            "1  /data/thesis/coco/images/train2017/00000032214...   \n",
            "2  /data/thesis/coco/images/train2017/00000001697...   \n",
            "3  /data/thesis/coco/images/train2017/00000010614...   \n",
            "4  /data/thesis/coco/images/train2017/00000010614...   \n",
            "\n",
            "                                             caption  \n",
            "0  A bicycle replica with a clock as the front wh...  \n",
            "1  A room with blue walls and a white sink and door.  \n",
            "2  A car that seems to be parked illegally behind...  \n",
            "3  A large passenger airplane flying through the ...  \n",
            "4  There is a GOL plane taking off in a partly cl...  \n",
            "\n",
            "Dataset created with 616767 samples\n",
            "\n",
            "DataLoader created with 151 batches\n",
            "Batch size: 512\n",
            "Number of workers: 32\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(csv_path)\n",
        "print(f\"Dataset loaded: {len(df)} images\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Create dataset\n",
        "dataset = UnifiedImageDataset(\n",
        "    df.rename(columns={\"local_path\": \"file_path\"}), \n",
        "    mode=\"file_df\",\n",
        "    size=(224, 224)\n",
        ")\n",
        "\n",
        "print(f\"\\nDataset created with {len(dataset)} samples\")\n",
        "\n",
        "# Create data loader with optimal settings\n",
        "num_cpu = cpu_count()\n",
        "num_workers = min(32, max(8, num_cpu // 8))\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=4096,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=6,\n",
        "    pin_memory_device=\"cuda\" if torch.cuda.is_available() else None,\n",
        ")\n",
        "\n",
        "print(f\"\\nDataLoader created with {len(loader)} batches\")\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Number of workers: {num_workers}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Generate Features and Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating CLIP embeddings...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "HF laion/CLIP-ViT-bigG-14-laion2B-39B-b160k batched encode (global):   0%|                                                                                                                                           | 0/1205 [00:00<?, ?it/s]/data/degis/degis/features/clip_embeddings_xl_hf.py:133: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(dtype=torch.float16):\n",
            "HF laion/CLIP-ViT-bigG-14-laion2B-39B-b160k batched encode (global): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1205/1205 [1:34:33<00:00,  4.71s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2192 Saved embeddings to /data/thesis/models/hf_xl_coco_embeddings.npy (shape=(616767, 1280), dim=1280)\n",
            "Saved: /data/thesis/models/hf_xl_coco_embeddings.npy, shape: (616767, 1280)\n",
            "\u2713 Generated embeddings with shape: (616767, 1280)\n",
            "\n",
            "Generating color histograms...\n",
            "### Color Histogram Generation [FAST, HCL] ###\n",
            "Total images: 616767, Bins: 8, Dimensions: 514\n",
            "Loaded from /data/thesis/data/adimagenet_color_histograms_hcl_514.npy\n",
            "\u2713 Generated HCL histograms with shape: (2080, 514)\n",
            "\n",
            "Generating edge maps...\n",
            "[\u2713] Loaded cached edge maps from /data/thesis/data/adimagenet_edge_maps.npy\n",
            "\u2713 Generated edge maps with shape: (2080, 50176)\n",
            "\n",
            "Training color disentanglement model...\n",
            "Run dir: /data/degis/runs/color_hcl514_tk100_b4096-20250911-101203\n",
            "Rest dir: /data/degis/runs/rest_hcl514_tk100_b4096-20250911-101203\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Embeddings and histograms must share N",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Train the color disentanglement model\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining color disentanglement model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m results = \u001b[43mdegis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_color_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistograms_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolour_hist_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhist_kind\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhcl514\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblur\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlambda_ortho\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweighting\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\u2713 Training complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOutput directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33moutput_dir\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/data/degis/degis/core/training.py:85\u001b[39m, in \u001b[36mtrain_color_model\u001b[39m\u001b[34m(embeddings_path, histograms_path, output_dir, hist_kind, epochs, batch_size, val_batch_size, lr, weight_decay, blur, lambda_ortho, lambda_consistency, top_k, weighting, device, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m emb = np.load(embeddings_path).astype(np.float32, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     84\u001b[39m hist = np.load(histograms_path).astype(np.float32, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m emb.shape[\u001b[32m0\u001b[39m] == hist.shape[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mEmbeddings and histograms must share N\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     87\u001b[39m N, clip_dim = emb.shape\n\u001b[32m     88\u001b[39m hist_dim = hist.shape[\u001b[32m1\u001b[39m]\n",
            "\u001b[31mAssertionError\u001b[39m: Embeddings and histograms must share N"
          ]
        }
      ],
      "source": [
        "# Generate CLIP embeddings using the package\n",
        "print(\"Generating CLIP embeddings...\")\n",
        "if embeddings_size == \"xl\":  \n",
        "    embeddings = degis.generate_xl_embeddings(\n",
        "        csv_path=csv_path,\n",
        "        output_path=embeddings_path,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        force_recompute=True\n",
        "    )\n",
        "else:\n",
        "    embeddings = degis.generate_clip_embeddings(\n",
        "        csv_path=csv_path,\n",
        "        output_path=embeddings_path,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        force_recompute=True\n",
        "    )\n",
        "print(f\"\u2713 Generated embeddings with shape: {embeddings.shape}\")\n",
        "\n",
        "# Generate color histograms\n",
        "print(\"\\nGenerating color histograms...\")\n",
        "histograms = degis.generate_color_histograms(\n",
        "    loader=loader,\n",
        "    hist_path=colour_hist_path,\n",
        "    hist_bins=8,\n",
        "    force_recompute=False,\n",
        "    color_space=\"hcl\"\n",
        ")\n",
        "print(f\"\u2713 Generated HCL histograms with shape: {histograms.shape}\")\n",
        "\n",
        "# Generate edge maps\n",
        "print(\"\\nGenerating edge maps...\")\n",
        "edge_maps = degis.generate_edge_maps(\n",
        "    loader=loader,\n",
        "    edge_maps_path=edge_maps_path,\n",
        "    method=\"canny\",\n",
        "    force_recompute=False\n",
        ")\n",
        "print(f\"\u2713 Generated edge maps with shape: {edge_maps.shape}\")\n",
        "\n",
        "# Train the color disentanglement model\n",
        "print(\"\\nTraining color disentanglement model...\")\n",
        "results = degis.train_color_model(\n",
        "    embeddings_path=embeddings_path,\n",
        "    histograms_path=colour_hist_path,\n",
        "    hist_kind=\"hcl514\",\n",
        "    epochs=200,\n",
        "    batch_size=4096,\n",
        "    val_batch_size=8192,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-2,\n",
        "    blur=0.05,\n",
        "    lambda_ortho=0.1,\n",
        "    top_k=100,\n",
        "    weighting=True,\n",
        ")\n",
        "\n",
        "print(f\"\\n\u2713 Training complete!\")\n",
        "print(f\"Output directory: {results['output_dir']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DEGIS Environment",
      "language": "python",
      "name": "degis"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}