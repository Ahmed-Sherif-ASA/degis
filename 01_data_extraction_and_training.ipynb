{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Extraction and Training with DEGIS Package\n",
        "\n",
        "This notebook demonstrates how to use the DEGIS package to:\n",
        "1. Extract CLIP embeddings from images\n",
        "2. Generate color histograms and edge maps\n",
        "3. Train color disentanglement models\n",
        "\n",
        "Based on the logic from `main.py` but using the new package structure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the package in development mode if needed\n",
        "# !pip install -e .\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from multiprocessing import cpu_count\n",
        "import os\n",
        "import time\n",
        "import platform\n",
        "import psutil\n",
        "import shutil\n",
        "\n",
        "# Import the DEGIS package\n",
        "import degis\n",
        "from degis.data.dataset import UnifiedImageDataset\n",
        "from degis.config import CSV_PATH, BATCH_SIZE, HF_XL_EMBEDDINGS_TARGET_PATH, COLOR_HIST_PATH_HCL_514, EDGE_MAPS_PATH\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. System Profiling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_system_profile():\n",
        "    print(\"=== SYSTEM PROFILE ===\")\n",
        "    print(\"Python:\", platform.python_version())\n",
        "    print(\"PyTorch:\", torch.__version__)\n",
        "    print(\"CPU cores:\", psutil.cpu_count(logical=True))\n",
        "    vm = psutil.virtual_memory()\n",
        "    print(f\"RAM: {vm.total/1e9:.1f} GB, free {vm.available/1e9:.1f} GB\")\n",
        "    \n",
        "    # Check if /data exists, otherwise check current directory\n",
        "    if os.path.exists(\"/data\"):\n",
        "        du = shutil.disk_usage(\"/data\")\n",
        "        print(f\"/data disk: total {du.total/1e9:.1f} GB, free {du.free/1e9:.1f} GB\")\n",
        "    else:\n",
        "        du = shutil.disk_usage(\".\")\n",
        "        print(f\"Current disk: total {du.total/1e9:.1f} GB, free {du.free/1e9:.1f} GB\")\n",
        "    \n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        i = torch.cuda.current_device()\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(i))\n",
        "        print(f\"VRAM total: {torch.cuda.get_device_properties(i).total_memory/1e9:.1f} GB\")\n",
        "    print(\"======================\")\n",
        "\n",
        "print_system_profile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Dataset and Create Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(f\"Dataset loaded: {len(df)} images\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Create dataset\n",
        "dataset = UnifiedImageDataset(\n",
        "    df.rename(columns={\"local_path\": \"file_path\"}), \n",
        "    mode=\"file_df\",\n",
        "    size=(224, 224)\n",
        ")\n",
        "\n",
        "print(f\"\\nDataset created with {len(dataset)} samples\")\n",
        "\n",
        "# Create data loader with optimal settings\n",
        "num_cpu = cpu_count()\n",
        "num_workers = min(32, max(8, num_cpu // 8))\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=6,\n",
        "    pin_memory_device=\"cuda\" if torch.cuda.is_available() else None,\n",
        ")\n",
        "\n",
        "print(f\"\\nDataLoader created with {len(loader)} batches\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Number of workers: {num_workers}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Generate Features and Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate CLIP embeddings using the package\n",
        "print(\"Generating CLIP embeddings...\")\n",
        "embeddings = degis.generate_xl_embeddings(\n",
        "    csv_path=CSV_PATH,\n",
        "    output_path=HF_XL_EMBEDDINGS_TARGET_PATH,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=num_workers,\n",
        "    force_recompute=True  # Set to False to skip if already exists\n",
        ")\n",
        "print(f\"✓ Generated embeddings with shape: {embeddings.shape}\")\n",
        "\n",
        "# Generate color histograms\n",
        "print(\"\\nGenerating color histograms...\")\n",
        "histograms = degis.generate_hcl_histograms(\n",
        "    loader=loader,\n",
        "    output_path=COLOR_HIST_PATH_HCL_514,\n",
        "    bins=8,\n",
        "    force_recompute=True\n",
        ")\n",
        "print(f\"✓ Generated HCL histograms with shape: {histograms.shape}\")\n",
        "\n",
        "# Generate edge maps\n",
        "print(\"\\nGenerating edge maps...\")\n",
        "edge_maps = degis.generate_edge_maps(\n",
        "    loader=loader,\n",
        "    output_path=EDGE_MAPS_PATH,\n",
        "    method=\"canny\",\n",
        "    force_recompute=True\n",
        ")\n",
        "print(f\"✓ Generated edge maps with shape: {edge_maps.shape}\")\n",
        "\n",
        "# Train the color disentanglement model\n",
        "print(\"\\nTraining color disentanglement model...\")\n",
        "results = degis.train_color_model(\n",
        "    embeddings_path=HF_XL_EMBEDDINGS_TARGET_PATH,\n",
        "    histograms_path=COLOR_HIST_PATH_HCL_514,\n",
        "    hist_kind=\"hcl514\",\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    val_batch_size=256,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-2,\n",
        "    blur=0.05,\n",
        "    lambda_ortho=0.1,\n",
        "    top_k=None,\n",
        "    weighting=False,\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Training complete!\")\n",
        "print(f\"Output directory: {results['output_dir']}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
