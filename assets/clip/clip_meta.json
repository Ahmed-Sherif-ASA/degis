{
  "clip_vit_h14": {
    "source": "open_clip",
    "model_name": "ViT-H-14",
    "pretrained": "laion2b_s32b_b79k",
    "embedding_dim": 1024,
    "dtype_runtime": "fp16_on_cuda, cast_to_fp32_on_save",
    "normalize": "none (downstream code may L2-normalize)"
  },
  "clip_vit_bigg14": {
    "source": "transformers",
    "model_id": "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k",
    "embedding_api": "CLIPVisionModelWithProjection.image_embeds",
    "projection_dim": 1280,
    "dtype_runtime": "fp16_on_cuda, cast_to_fp32_on_save",
    "normalize": "L2 normalization applied (see code compute_clip_embedding_xl)"
  }
}