{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bfd2012",
   "metadata": {},
   "source": [
    "# Notes on Reproducibility:\n",
    "These scripts were used to download images and generate the data manifests employed during training and evaluation. They represent the actual runs that produced the manifests used in this dissertation project.\n",
    "While the scripts remain functional and can be executed successfully, their outputs may differ if the underlying data sources have changed since the original collection.\n",
    "For access to the exact manifests used in this work, please contact the author."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa8e51",
   "metadata": {},
   "source": [
    "# LAION 2B - Download Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b721d5e-150f-47fe-a680-340ab45ec883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47638f4122ec40f0b8be991e698965dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting batch 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|██████████| 50000/50000 [04:45<00:00, 175.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 1 complete. Saved 33579 records so far.\n",
      "\n",
      "=== Starting batch 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 2: 100%|██████████| 50000/50000 [06:00<00:00, 138.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 2 complete. Saved 67055 records so far.\n",
      "\n",
      "=== Starting batch 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 3: 100%|██████████| 50000/50000 [06:43<00:00, 124.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 3 complete. Saved 100362 records so far.\n",
      "\n",
      "=== Starting batch 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|██████████| 50000/50000 [07:37<00:00, 109.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 4 complete. Saved 133839 records so far.\n",
      "\n",
      "=== Starting batch 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 5: 100%|██████████| 50000/50000 [07:11<00:00, 115.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 5 complete. Saved 167332 records so far.\n",
      "\n",
      "=== Starting batch 6 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 6: 100%|██████████| 50000/50000 [07:06<00:00, 117.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 6 complete. Saved 200988 records so far.\n",
      "\n",
      "=== Starting batch 7 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 7: 100%|██████████| 50000/50000 [07:13<00:00, 115.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 7 complete. Saved 234383 records so far.\n",
      "\n",
      "=== Starting batch 8 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 8: 100%|██████████| 50000/50000 [08:25<00:00, 98.93it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 8 complete. Saved 267846 records so far.\n",
      "\n",
      "=== Starting batch 9 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 9: 100%|██████████| 50000/50000 [08:10<00:00, 101.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 9 complete. Saved 300877 records so far.\n",
      "\n",
      "=== Starting batch 10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:935: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n",
      "Batch 10:  65%|██████▍   | 32318/50000 [04:07<02:25, 121.20it/s]/venv/main/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:935: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "Batch 10: 100%|██████████| 50000/50000 [08:55<00:00, 93.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 10 complete. Saved 334407 records so far.\n",
      "\n",
      "=== Starting batch 11 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 11:  45%|████▍     | 22317/50000 [02:44<05:14, 88.16it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Batch 13: 100%|██████████| 50000/50000 [07:48<00:00, 106.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 13 complete. Saved 434478 records so far.\n",
      "\n",
      "=== Starting batch 14 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 14: 100%|██████████| 50000/50000 [07:00<00:00, 118.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 14 complete. Saved 467758 records so far.\n",
      "\n",
      "=== Starting batch 15 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 15: 100%|██████████| 50000/50000 [07:19<00:00, 113.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 15 complete. Saved 501047 records so far.\n",
      "\n",
      "=== Starting batch 16 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 16: 100%|██████████| 50000/50000 [07:21<00:00, 113.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 16 complete. Saved 534518 records so far.\n",
      "\n",
      "=== Starting batch 17 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 17: 100%|██████████| 50000/50000 [07:02<00:00, 118.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 17 complete. Saved 567911 records so far.\n",
      "\n",
      "=== Starting batch 18 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 18: 100%|██████████| 50000/50000 [07:13<00:00, 115.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 18 complete. Saved 601385 records so far.\n",
      "\n",
      "=== Starting batch 19 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 19: 100%|██████████| 50000/50000 [07:35<00:00, 109.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 19 complete. Saved 634802 records so far.\n",
      "\n",
      "=== Starting batch 20 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 20: 100%|██████████| 50000/50000 [07:08<00:00, 116.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 20 complete. Saved 668109 records so far.\n",
      "\n",
      "=== Starting batch 21 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 21: 100%|██████████| 50000/50000 [07:10<00:00, 116.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 21 complete. Saved 701344 records so far.\n",
      "\n",
      "=== Starting batch 22 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 22: 100%|██████████| 50000/50000 [07:06<00:00, 117.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 22 complete. Saved 734644 records so far.\n",
      "\n",
      "=== Starting batch 23 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 23: 100%|██████████| 50000/50000 [07:07<00:00, 116.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 23 complete. Saved 768159 records so far.\n",
      "\n",
      "=== Starting batch 24 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 24: 100%|██████████| 50000/50000 [06:52<00:00, 121.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 24 complete. Saved 801781 records so far.\n",
      "\n",
      "=== Starting batch 25 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 25: 100%|██████████| 50000/50000 [07:04<00:00, 117.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 25 complete. Saved 835091 records so far.\n",
      "\n",
      "=== Starting batch 26 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 26: 100%|██████████| 50000/50000 [07:13<00:00, 115.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 26 complete. Saved 868706 records so far.\n",
      "\n",
      "=== Starting batch 27 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 27: 100%|██████████| 50000/50000 [06:59<00:00, 119.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 27 complete. Saved 902188 records so far.\n",
      "\n",
      "=== Starting batch 28 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 28: 100%|██████████| 50000/50000 [07:46<00:00, 107.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 28 complete. Saved 935570 records so far.\n",
      "\n",
      "=== Starting batch 29 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 29: 100%|██████████| 50000/50000 [07:10<00:00, 116.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 29 complete. Saved 968873 records so far.\n",
      "\n",
      "=== Starting batch 30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 30: 100%|██████████| 50000/50000 [06:38<00:00, 125.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 30 complete. Saved 1002481 records so far.\n",
      "\n",
      "=== Starting batch 31 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 31: 100%|██████████| 50000/50000 [07:09<00:00, 116.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 31 complete. Saved 1035872 records so far.\n",
      "\n",
      "=== Starting batch 32 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 32: 100%|██████████| 50000/50000 [07:06<00:00, 117.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 32 complete. Saved 1069257 records so far.\n",
      "\n",
      "=== Starting batch 33 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 33: 100%|██████████| 50000/50000 [07:18<00:00, 114.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 33 complete. Saved 1102616 records so far.\n",
      "\n",
      "=== Starting batch 34 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 34: 100%|██████████| 50000/50000 [07:32<00:00, 110.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 34 complete. Saved 1136228 records so far.\n",
      "\n",
      "=== Starting batch 35 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 35: 100%|██████████| 50000/50000 [06:59<00:00, 119.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 35 complete. Saved 1169923 records so far.\n",
      "\n",
      "=== Starting batch 36 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 36: 100%|██████████| 50000/50000 [07:45<00:00, 107.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 36 complete. Saved 1203271 records so far.\n",
      "\n",
      "=== Starting batch 37 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 37: 100%|██████████| 50000/50000 [07:03<00:00, 118.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 37 complete. Saved 1236588 records so far.\n",
      "\n",
      "=== Starting batch 38 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 38: 100%|██████████| 50000/50000 [07:18<00:00, 114.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 38 complete. Saved 1269932 records so far.\n",
      "\n",
      "=== Starting batch 39 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 39:  64%|██████▍   | 32017/50000 [03:47<02:34, 116.43it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Batch 57: 100%|██████████| 50000/50000 [06:39<00:00, 125.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 57 complete. Saved 1902866 records so far.\n",
      "\n",
      "=== Starting batch 58 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 58:  70%|███████   | 35101/50000 [04:23<02:17, 108.46it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Batch 63: 100%|██████████| 50000/50000 [06:57<00:00, 119.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 63 complete. Saved 2102807 records so far.\n",
      "\n",
      "=== Starting batch 64 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 64: 100%|██████████| 50000/50000 [06:46<00:00, 123.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 64 complete. Saved 2135957 records so far.\n",
      "\n",
      "=== Starting batch 65 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 65: 100%|██████████| 50000/50000 [06:43<00:00, 123.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 65 complete. Saved 2169228 records so far.\n",
      "\n",
      "=== Starting batch 66 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 66: 100%|██████████| 50000/50000 [07:32<00:00, 110.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 66 complete. Saved 2202505 records so far.\n",
      "\n",
      "=== Starting batch 67 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 67: 100%|██████████| 50000/50000 [07:05<00:00, 117.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 67 complete. Saved 2236026 records so far.\n",
      "\n",
      "=== Starting batch 68 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 68: 100%|██████████| 50000/50000 [06:59<00:00, 119.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 68 complete. Saved 2269319 records so far.\n",
      "\n",
      "=== Starting batch 69 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 69: 100%|██████████| 50000/50000 [07:02<00:00, 118.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 69 complete. Saved 2302855 records so far.\n",
      "\n",
      "=== Starting batch 70 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 70: 100%|██████████| 50000/50000 [06:42<00:00, 124.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 70 complete. Saved 2336397 records so far.\n",
      "\n",
      "=== Starting batch 71 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 71: 100%|██████████| 50000/50000 [07:01<00:00, 118.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 71 complete. Saved 2369695 records so far.\n",
      "\n",
      "=== Starting batch 72 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 72: 100%|██████████| 50000/50000 [07:05<00:00, 117.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 72 complete. Saved 2403203 records so far.\n",
      "\n",
      "=== Starting batch 73 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 73:  92%|█████████▏| 46232/50000 [05:51<00:31, 118.40it/s]/venv/main/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:935: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n",
      "Batch 73: 100%|██████████| 50000/50000 [07:25<00:00, 112.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 73 complete. Saved 2436397 records so far.\n",
      "\n",
      "=== Starting batch 74 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 74: 100%|██████████| 50000/50000 [07:14<00:00, 115.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 74 complete. Saved 2469575 records so far.\n",
      "\n",
      "=== Starting batch 75 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 75: 100%|██████████| 50000/50000 [07:18<00:00, 114.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 75 complete. Saved 2502905 records so far.\n",
      "\n",
      "=== Starting batch 76 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 76: 100%|██████████| 50000/50000 [06:44<00:00, 123.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 76 complete. Saved 2536294 records so far.\n",
      "\n",
      "=== Starting batch 77 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 77: 100%|██████████| 50000/50000 [07:27<00:00, 111.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 77 complete. Saved 2569569 records so far.\n",
      "\n",
      "=== Starting batch 78 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 78: 100%|██████████| 50000/50000 [07:04<00:00, 117.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 78 complete. Saved 2602851 records so far.\n",
      "\n",
      "=== Starting batch 79 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 79: 100%|██████████| 50000/50000 [07:23<00:00, 112.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 79 complete. Saved 2636186 records so far.\n",
      "\n",
      "=== Starting batch 80 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 80: 100%|██████████| 50000/50000 [07:01<00:00, 118.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 80 complete. Saved 2669432 records so far.\n",
      "\n",
      "=== Starting batch 81 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 81: 100%|██████████| 50000/50000 [06:57<00:00, 119.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 81 complete. Saved 2702651 records so far.\n",
      "\n",
      "=== Starting batch 82 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 82: 100%|██████████| 50000/50000 [07:05<00:00, 117.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 82 complete. Saved 2736058 records so far.\n",
      "\n",
      "=== Starting batch 83 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 83: 100%|██████████| 50000/50000 [06:51<00:00, 121.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 83 complete. Saved 2769632 records so far.\n",
      "\n",
      "=== Starting batch 84 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 84: 100%|██████████| 50000/50000 [06:57<00:00, 119.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 84 complete. Saved 2802908 records so far.\n",
      "\n",
      "=== Starting batch 85 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 85: 100%|██████████| 50000/50000 [06:49<00:00, 122.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 85 complete. Saved 2836460 records so far.\n",
      "\n",
      "=== Starting batch 86 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 86: 100%|██████████| 50000/50000 [07:03<00:00, 118.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 86 complete. Saved 2869767 records so far.\n",
      "\n",
      "=== Starting batch 87 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 87: 100%|██████████| 50000/50000 [06:51<00:00, 121.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 87 complete. Saved 2903112 records so far.\n",
      "\n",
      "=== Starting batch 88 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 88: 100%|██████████| 50000/50000 [07:06<00:00, 117.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 88 complete. Saved 2936573 records so far.\n",
      "\n",
      "=== Starting batch 89 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 89: 100%|██████████| 50000/50000 [07:19<00:00, 113.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 89 complete. Saved 2970095 records so far.\n",
      "\n",
      "=== Starting batch 90 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 90: 100%|██████████| 50000/50000 [06:58<00:00, 119.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 90 complete. Saved 3003287 records so far.\n",
      "\n",
      "=== Starting batch 91 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 91: 100%|██████████| 50000/50000 [07:03<00:00, 118.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 91 complete. Saved 3036634 records so far.\n",
      "\n",
      "=== Starting batch 92 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 92: 100%|██████████| 50000/50000 [06:28<00:00, 128.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 92 complete. Saved 3069985 records so far.\n",
      "\n",
      "=== Starting batch 93 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 93: 100%|██████████| 50000/50000 [07:43<00:00, 107.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 93 complete. Saved 3103125 records so far.\n",
      "\n",
      "=== Starting batch 94 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 94: 100%|██████████| 50000/50000 [07:07<00:00, 117.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 94 complete. Saved 3136506 records so far.\n",
      "\n",
      "=== Starting batch 95 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 95: 100%|██████████| 50000/50000 [06:51<00:00, 121.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 95 complete. Saved 3169774 records so far.\n",
      "\n",
      "=== Starting batch 96 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 96: 100%|██████████| 50000/50000 [06:51<00:00, 121.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 96 complete. Saved 3202920 records so far.\n",
      "\n",
      "=== Starting batch 97 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 97: 100%|██████████| 50000/50000 [07:20<00:00, 113.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 97 complete. Saved 3236029 records so far.\n",
      "\n",
      "=== Starting batch 98 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 98: 100%|██████████| 50000/50000 [07:08<00:00, 116.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 98 complete. Saved 3269368 records so far.\n",
      "\n",
      "=== Starting batch 99 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 99: 100%|██████████| 50000/50000 [06:53<00:00, 120.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 99 complete. Saved 3302936 records so far.\n",
      "\n",
      "=== Starting batch 100 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 100: 100%|██████████| 50000/50000 [06:52<00:00, 121.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Batch 100 complete. Saved 3336240 records so far.\n",
      "\n",
      "🎉 Done. Total records saved: 3336240\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import itertools, os, requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ======================\n",
    "# Config\n",
    "# ======================\n",
    "total_size  = 5_000_000    # adjust as needed\n",
    "batch_size  = 50_000       # safe batch size for progress + memory\n",
    "output_dir  = \"/data/thesis/laion_5m_images\"\n",
    "csv_path    = \"/data/thesis/laion_5m_manifest.csv\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ======================\n",
    "# Load dataset (streaming)\n",
    "# ======================\n",
    "ds = load_dataset(\n",
    "    \"laion/laion2B-en-aesthetic\",\n",
    "    split=\"train\",\n",
    "    streaming=True,\n",
    "    token=os.environ[\"HF_TOKEN\"]  # assumes token is in env\n",
    ")\n",
    "\n",
    "def good(example):\n",
    "    return float(example.get(\"aesthetic\", 0)) >= 5.0\n",
    "\n",
    "stream = filter(good, ds)\n",
    "\n",
    "# ======================\n",
    "# Download function\n",
    "# ======================\n",
    "def fetch_and_save(idx, ex, output_dir):\n",
    "    url = ex.get(\"URL\") or ex.get(\"url\")\n",
    "    caption = ex.get(\"TEXT\") or ex.get(\"text\")\n",
    "    aesthetic = ex.get(\"aesthetic\", 0)\n",
    "    local_path = os.path.join(output_dir, f\"{idx:07d}.jpg\")\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "        if r.status_code == 200:\n",
    "            img = Image.open(BytesIO(r.content)).convert(\"RGB\")\n",
    "            img.save(local_path, \"JPEG\")\n",
    "            return {\n",
    "                \"id\": idx,\n",
    "                \"url\": url,\n",
    "                \"caption\": caption,\n",
    "                \"aesthetic\": aesthetic,\n",
    "                \"local_path\": local_path,\n",
    "            }\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Batched Download Loop\n",
    "# ======================\n",
    "records = []\n",
    "for batch_start in range(0, total_size, batch_size):\n",
    "    print(f\"\\n=== Starting batch {batch_start//batch_size + 1} ===\")\n",
    "    batch_stream = itertools.islice(stream, batch_size)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=64) as executor:\n",
    "        futures = [executor.submit(fetch_and_save, i + batch_start, ex, output_dir)\n",
    "                   for i, ex in enumerate(batch_stream)]\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=batch_size, desc=f\"Batch {batch_start//batch_size + 1}\"):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                records.append(result)\n",
    "\n",
    "    # Save partial CSV after each batch\n",
    "    pd.DataFrame(records).to_csv(csv_path, index=False)\n",
    "    print(f\"✅ Batch {batch_start//batch_size + 1} complete. Saved {len(records)} records so far.\")\n",
    "\n",
    "\n",
    "print(f\"\\n🎉 Done. Total records saved: {len(records)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd991f",
   "metadata": {},
   "source": [
    "# COCO - Download Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fa5422-1d3b-4513-af7d-704f29d705bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train2017.zip:  83%|████████▎ | 16.0G/19.3G [13:05<02:05, 26.7MB/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "train2017.zip: 100%|██████████| 19.3G/19.3G [15:48<00:00, 20.4MB/s]\n",
      "val2017.zip: 100%|██████████| 816M/816M [00:50<00:00, 16.2MB/s] \n",
      "annotations_trainval2017.zip: 100%|██████████| 253M/253M [00:11<00:00, 22.6MB/s] \n",
      "Extract train2017.zip: 100%|██████████| 118288/118288 [00:48<00:00, 2450.52it/s]\n",
      "Extract val2017.zip: 100%|██████████| 5001/5001 [00:02<00:00, 2481.80it/s]\n",
      "Extract annotations_trainval2017.zip: 100%|██████████| 6/6 [00:03<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote manifest with 616767 rows to /data/thesis/coco2017/coco_manifest.csv\n",
      "   split  image_id         file_name  \\\n",
      "0  train    203564  000000203564.jpg   \n",
      "1  train    322141  000000322141.jpg   \n",
      "2  train     16977  000000016977.jpg   \n",
      "3  train    106140  000000106140.jpg   \n",
      "4  train    106140  000000106140.jpg   \n",
      "\n",
      "                                          local_path  \\\n",
      "0  /data/thesis/coco2017/images/train2017/0000002...   \n",
      "1  /data/thesis/coco2017/images/train2017/0000003...   \n",
      "2  /data/thesis/coco2017/images/train2017/0000000...   \n",
      "3  /data/thesis/coco2017/images/train2017/0000001...   \n",
      "4  /data/thesis/coco2017/images/train2017/0000001...   \n",
      "\n",
      "                                             caption  \n",
      "0  A bicycle replica with a clock as the front wh...  \n",
      "1  A room with blue walls and a white sink and door.  \n",
      "2  A car that seems to be parked illegally behind...  \n",
      "3  A large passenger airplane flying through the ...  \n",
      "4  There is a GOL plane taking off in a partly cl...  \n"
     ]
    }
   ],
   "source": [
    "import os, json, zipfile, hashlib, requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# ======================\n",
    "# Config\n",
    "# ======================\n",
    "root_dir   = Path(\"/data/thesis/coco2017\")\n",
    "img_dir    = root_dir / \"images\"   # will contain train2017/ and val2017/\n",
    "ann_dir    = root_dir / \"annotations\"\n",
    "csv_path   = root_dir / \"coco_manifest.csv\"\n",
    "\n",
    "root_dir.mkdir(parents=True, exist_ok=True)\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "ann_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Official COCO 2017 URLs (mirrors sometimes differ; these are the canonical ones)\n",
    "URLS = {\n",
    "    \"train_images\": (\"http://images.cocodataset.org/zips/train2017.zip\", img_dir),\n",
    "    \"val_images\":   (\"http://images.cocodataset.org/zips/val2017.zip\",   img_dir),\n",
    "    \"annotations\":  (\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\", ann_dir),\n",
    "}\n",
    "\n",
    "def download_with_progress(url: str, dest: Path):\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dest.exists() and dest.stat().st_size > 0:\n",
    "        print(f\"✔ Already present: {dest}\")\n",
    "        return dest\n",
    "    with requests.get(url, stream=True, timeout=60) as r:\n",
    "        r.raise_for_status()\n",
    "        total = int(r.headers.get(\"Content-Length\", 0))\n",
    "        tmp = dest.with_suffix(dest.suffix + \".part\")\n",
    "        with open(tmp, \"wb\") as f, tqdm(\n",
    "            total=total, unit=\"B\", unit_scale=True, desc=dest.name\n",
    "        ) as pbar:\n",
    "            for chunk in r.iter_content(chunk_size=1024 * 1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "        tmp.rename(dest)\n",
    "    return dest\n",
    "\n",
    "def safe_unzip(zip_path: Path, target_dir: Path):\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        for m in tqdm(zf.infolist(), desc=f\"Extract {zip_path.name}\"):\n",
    "            # basic zip-slip guard\n",
    "            out_path = target_dir / m.filename\n",
    "            if not str(out_path.resolve()).startswith(str(target_dir.resolve())):\n",
    "                raise RuntimeError(\"Zip path traversal detected\")\n",
    "            if m.is_dir():\n",
    "                out_path.mkdir(parents=True, exist_ok=True)\n",
    "            else:\n",
    "                out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                zf.extract(m, path=target_dir)\n",
    "\n",
    "# ======================\n",
    "# 1) Download zips\n",
    "# ======================\n",
    "downloaded = {}\n",
    "for key, (url, target_dir) in URLS.items():\n",
    "    fname = url.split(\"/\")[-1]\n",
    "    dest = target_dir / fname\n",
    "    downloaded[key] = download_with_progress(url, dest)\n",
    "\n",
    "# ======================\n",
    "# 2) Extract\n",
    "# ======================\n",
    "# Images go into img_dir (which already contains the zip). Each zip contains its own subfolder train2017/ or val2017/\n",
    "safe_unzip(downloaded[\"train_images\"], img_dir)\n",
    "safe_unzip(downloaded[\"val_images\"],   img_dir)\n",
    "# Annotations zip extracts json files into ann_dir/annotations/\n",
    "safe_unzip(downloaded[\"annotations\"],  ann_dir)\n",
    "\n",
    "# Resolve final paths\n",
    "train_img_root = img_dir / \"train2017\"\n",
    "val_img_root   = img_dir / \"val2017\"\n",
    "\n",
    "# Annotations usually end up in ann_dir/\"annotations\"/captions_train2017.json, etc.\n",
    "ann_root = ann_dir / \"annotations\"\n",
    "cap_train_json = ann_root / \"captions_train2017.json\"\n",
    "cap_val_json   = ann_root / \"captions_val2017.json\"\n",
    "\n",
    "assert train_img_root.exists(), f\"Missing {train_img_root}\"\n",
    "assert val_img_root.exists(),   f\"Missing {val_img_root}\"\n",
    "assert cap_train_json.exists(), f\"Missing {cap_train_json}\"\n",
    "assert cap_val_json.exists(),   f\"Missing {cap_val_json}\"\n",
    "\n",
    "# ======================\n",
    "# 3) Build CSV manifest from captions\n",
    "# ======================\n",
    "def build_manifest(captions_json: Path, split: str, images_root: Path):\n",
    "    with open(captions_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Map image_id -> file_name\n",
    "    id_to_name = {img[\"id\"]: img[\"file_name\"] for img in data[\"images\"]}\n",
    "    rows = []\n",
    "    for ann in data[\"annotations\"]:\n",
    "        image_id = ann[\"image_id\"]\n",
    "        caption  = ann.get(\"caption\", \"\").strip()\n",
    "        file_name = id_to_name.get(image_id)\n",
    "        if not file_name:\n",
    "            continue\n",
    "        local_path = str((images_root / file_name).resolve())\n",
    "        rows.append({\n",
    "            \"split\": split,\n",
    "            \"image_id\": image_id,\n",
    "            \"file_name\": file_name,\n",
    "            \"local_path\": local_path,\n",
    "            \"caption\": caption\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "records = []\n",
    "records += build_manifest(cap_train_json, \"train\", train_img_root)\n",
    "records += build_manifest(cap_val_json,   \"val\",   val_img_root)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"✅ Wrote manifest with {len(df)} rows to {csv_path}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfff29b",
   "metadata": {},
   "source": [
    "# AdImageNet - Download Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582bdeb0-eb3e-425b-8c74-a9d2cdbaf372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd92e986ed64a3ba32d9d997b795232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8a0efa2d1c46edbd6aea1515f135b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00002-6e587552aa3c8a(…):   0%|          | 0.00/344M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628aa9d06f174c70bc20a4ee1471f662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00002-823ac5dae71e0e(…):   0%|          | 0.00/338M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a217a3791d694fc4bec19b48d921baff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering & saving:   0%|          | 0/9003 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Filtering & saving: 100%|██████████| 9003/9003 [00:17<00:00, 519.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done. Kept 2080 creatives, skipped 6923.\n",
      "Images → /data/thesis/AdImageNet/images\n",
      "Manifest → /data/thesis/AdImageNet/adimagenet_manifest.csv\n"
     ]
    }
   ],
   "source": [
    "# AdImageNet: download → filter → save → manifest\n",
    "# Requirements:\n",
    "#   pip install -U datasets pillow pandas tqdm huggingface_hub\n",
    "\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import io, os, re, sys\n",
    "\n",
    "# ======================\n",
    "# Config\n",
    "# ======================\n",
    "OUT_ROOT   = Path(\"/data/thesis/AdImageNet\")\n",
    "IMG_DIR    = OUT_ROOT / \"images\"\n",
    "CSV_PATH   = OUT_ROOT / \"adimagenet_manifest.csv\"\n",
    "KEEP_TEXT_MAX_LEN = 80\n",
    "MIN_W = 250\n",
    "MIN_H = 250\n",
    "\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ======================\n",
    "# Load dataset\n",
    "# ======================\n",
    "# If you ever get 401/403: run `huggingface-cli login` in the same environment\n",
    "try:\n",
    "    ds = load_dataset(\"PeterBrendan/AdImageNet\", split=\"train\")\n",
    "except Exception:\n",
    "    dsdict = load_dataset(\"PeterBrendan/AdImageNet\")\n",
    "    ds = next(iter(dsdict.values()))\n",
    "\n",
    "# ======================\n",
    "# Helpers\n",
    "# ======================\n",
    "dim_re = re.compile(r\"\\d+\")\n",
    "\n",
    "def get_dims(record, pil_img: Image.Image | None):\n",
    "    \"\"\"\n",
    "    Return (w, h) using record['dimensions'] if present, otherwise PIL size.\n",
    "    \"\"\"\n",
    "    w = h = None\n",
    "    dims = record.get(\"dimensions\")\n",
    "    if isinstance(dims, str):\n",
    "        nums = dim_re.findall(dims)\n",
    "        if len(nums) >= 2:\n",
    "            w, h = int(nums[0]), int(nums[1])\n",
    "\n",
    "    if pil_img is not None:\n",
    "        pw, ph = pil_img.size\n",
    "        # prefer explicit dims if present; otherwise use PIL\n",
    "        w = w if w is not None else pw\n",
    "        h = h if h is not None else ph\n",
    "    return w, h\n",
    "\n",
    "def get_pil(record):\n",
    "    \"\"\"\n",
    "    Make a PIL.Image from the 'image' column (the dataset uses Image feature).\n",
    "    Also handles raw bytes/string path just in case.\n",
    "    \"\"\"\n",
    "    val = record.get(\"image\")\n",
    "    if isinstance(val, Image.Image):\n",
    "        return val.convert(\"RGB\")\n",
    "    if isinstance(val, (bytes, bytearray)):\n",
    "        return Image.open(io.BytesIO(val)).convert(\"RGB\")\n",
    "    if isinstance(val, str) and os.path.exists(val):\n",
    "        return Image.open(val).convert(\"RGB\")\n",
    "    raise KeyError(\"No usable image payload in record['image'].\")\n",
    "\n",
    "def pass_filters(record, pil_img):\n",
    "    # text length\n",
    "    txt = record.get(\"text\") or \"\"\n",
    "    if isinstance(txt, str) and len(txt) > KEEP_TEXT_MAX_LEN:\n",
    "        return False\n",
    "\n",
    "    # dimensions (require BOTH width & height ≥ thresholds)\n",
    "    w, h = get_dims(record, pil_img)\n",
    "    if w is None or h is None:\n",
    "        return False\n",
    "    return (w >= MIN_W) and (h >= MIN_H)\n",
    "\n",
    "# ======================\n",
    "# Save loop + manifest\n",
    "# ======================\n",
    "rows = []\n",
    "kept = 0\n",
    "skipped = 0\n",
    "\n",
    "for i, rec in enumerate(tqdm(ds, desc=\"Filtering & saving\")):\n",
    "    try:\n",
    "        img = get_pil(rec)\n",
    "        if not pass_filters(rec, img):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        # organize optionally by dimensions folder, e.g. \"(300, 250)\"\n",
    "        sub = str(rec.get(\"dimensions\") or \"\")\n",
    "        save_dir = IMG_DIR / sub if sub else IMG_DIR\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # filename: prefer dataset file_name, else generate\n",
    "        fname = rec.get(\"file_name\") or f\"ad_{i:06d}.jpg\"\n",
    "        # normalize extension to .jpg\n",
    "        stem, ext = os.path.splitext(fname)\n",
    "        if ext.lower() not in [\".jpg\", \".jpeg\", \".png\", \".webp\"]:\n",
    "            fname = f\"{stem}.jpg\"\n",
    "\n",
    "        out_path = save_dir / fname\n",
    "        img.save(out_path, format=\"JPEG\", quality=95, optimize=True)\n",
    "\n",
    "        w, h = get_dims(rec, img)\n",
    "        rows.append({\n",
    "            \"file_path\": str(out_path.resolve()),\n",
    "            \"file_name\": fname,\n",
    "            \"text\": rec.get(\"text\") or \"\",\n",
    "            \"dimensions\": rec.get(\"dimensions\") or \"\",\n",
    "            \"width\": w, \"height\": h,\n",
    "        })\n",
    "        kept += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        skipped += 1\n",
    "        print(f\"[warn] row {i}: {e}\", file=sys.stderr)\n",
    "\n",
    "# ======================\n",
    "# Write manifest\n",
    "# ======================\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "\n",
    "print(f\"\\nDone. Kept {kept} creatives, skipped {skipped}.\")\n",
    "print(f\"Images → {IMG_DIR}\")\n",
    "print(f\"Manifest → {CSV_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
