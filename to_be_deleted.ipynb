{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5559cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package in development mode if needed\n",
    "# !pip install -e .\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from multiprocessing import cpu_count\n",
    "import os\n",
    "import time\n",
    "import platform\n",
    "import psutil\n",
    "import shutil\n",
    "\n",
    "# Import the DEGIS package\n",
    "import degis\n",
    "from degis.data.dataset import UnifiedImageDataset\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781e2cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ cost_rgb512.npy  shape=(512, 512)  sha256=5c8ac2fb072dd176\n",
      "✓ cost_lab514.npy  shape=(514, 514)  sha256=3ba7d8807f777a4c\n",
      "✓ cost_hcl514.npy  shape=(514, 514)  sha256=46db118d1adf911a\n"
     ]
    }
   ],
   "source": [
    "# build_cost_matrices.py\n",
    "# Creates ground-cost matrices consistent with your *fast* histograms:\n",
    "# - RGB512  : bins over [0,256) for each channel (8×8×8 = 512 bins)\n",
    "# - LAB514  : same 8×8×8 grid but mapped back to (L*,a*,b*), plus 2 neutral bins (black, white)\n",
    "# - HCL514  : L*∈[0,100], C∈[0,c_max], H∈[0,360); mapped to (L*,a*,b*) via a=C cosH, b=C sinH; + neutrals\n",
    "#\n",
    "# Output: cost_rgb512.npy, cost_lab514.npy, cost_hcl514.npy  (float32, symmetric, zero diagonal)\n",
    "\n",
    "import os, hashlib\n",
    "import numpy as np\n",
    "\n",
    "# --------------------------- helpers ---------------------------------\n",
    "def bin_centers(low: float, high: float, bins: int) -> np.ndarray:\n",
    "    edges = np.linspace(low, high, bins + 1, dtype=np.float64)\n",
    "    return (edges[:-1] + edges[1:]) * 0.5  # midpoints (float64)\n",
    "\n",
    "def grid_centers(c1, c2, c3) -> np.ndarray:\n",
    "    X, Y, Z = np.meshgrid(c1, c2, c3, indexing=\"ij\")\n",
    "    P = np.stack([X, Y, Z], axis=-1).reshape(-1, 3)\n",
    "    return P  # [K,3] float64\n",
    "\n",
    "def pairwise_euclidean(X: np.ndarray) -> np.ndarray:\n",
    "    # X: [K,3] float64 -> returns [K,K] float32\n",
    "    diff = X[:, None, :] - X[None, :, :]\n",
    "    D = np.sqrt((diff * diff).sum(axis=-1), dtype=np.float64)\n",
    "    return D.astype(np.float32)\n",
    "\n",
    "def add_neutral_bins(points_Lab: np.ndarray) -> np.ndarray:\n",
    "    # points_Lab: [K,3] in (L*, a*, b*)\n",
    "    black = np.array([[0.0,   0.0, 0.0]])\n",
    "    white = np.array([[100.0, 0.0, 0.0]])\n",
    "    return np.vstack([points_Lab, black, white])\n",
    "\n",
    "def check_and_save(M: np.ndarray, path: str):\n",
    "    assert M.ndim == 2 and M.shape[0] == M.shape[1], f\"Not square: {M.shape}\"\n",
    "    assert np.allclose(M, M.T, atol=1e-6), \"Matrix not symmetric\"\n",
    "    assert np.allclose(np.diag(M), 0.0, atol=1e-6), \"Diagonal not zero\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    np.save(path, M.astype(np.float32))\n",
    "    h = hashlib.sha256(open(path, \"rb\").read()).hexdigest()[:16]\n",
    "    print(f\"✓ {os.path.basename(path)}  shape={M.shape}  sha256={h}\")\n",
    "\n",
    "# --------------------------- builders --------------------------------\n",
    "def build_rgb_cost(bins: int = 8) -> np.ndarray:\n",
    "    # histogram space: R,G,B ∈ [0,256) as in fast_rgb_histogram\n",
    "    c = bin_centers(0.0, 256.0, bins)         # e.g., [16, 48, ..., 240]\n",
    "    P = grid_centers(c, c, c)                 # [512,3] in RGB units\n",
    "    return pairwise_euclidean(P)\n",
    "\n",
    "def build_lab_cost(bins: int = 8) -> np.ndarray:\n",
    "    # histogram space used 0..255 buckets after transforms:\n",
    "    # L8 in [0,256) corresponds to L* via L* = L8 * 100/255\n",
    "    # a8 = a* + 128, b8 = b* + 128\n",
    "    c8 = bin_centers(0.0, 256.0, bins)        # midpoints in 0..256\n",
    "    Ls = c8 * (100.0 / 255.0)                 # back to L* domain\n",
    "    As = c8 - 128.0                           # back to a*\n",
    "    Bs = c8 - 128.0                           # back to b*\n",
    "    P = grid_centers(Ls, As, Bs)              # [512,3] in (L*,a*,b*)\n",
    "    P = add_neutral_bins(P)                   # + black/white => [514,3]\n",
    "    return pairwise_euclidean(P)\n",
    "\n",
    "def build_hcl_cost(bins: int = 8, c_max: float = 150.0) -> np.ndarray:\n",
    "    # histogram space: L*∈[0,100], C∈[0,c_max], H∈[0,360)\n",
    "    Lc = bin_centers(0.0, 100.0, bins)\n",
    "    Cc = bin_centers(0.0, c_max, bins)\n",
    "    Hc = bin_centers(0.0, 360.0, bins)        # degrees\n",
    "    # Build grid in (L*,C,H), then map (C,H) -> (a*,b*)\n",
    "    Lg, Cg, Hg = np.meshgrid(Lc, Cc, Hc, indexing=\"ij\")\n",
    "    a = Cg * np.cos(np.deg2rad(Hg))\n",
    "    b = Cg * np.sin(np.deg2rad(Hg))\n",
    "    P = np.stack([Lg, a, b], axis=-1).reshape(-1, 3)  # [512,3] in (L*,a*,b*)\n",
    "    P = add_neutral_bins(P)                            # [514,3]\n",
    "    return pairwise_euclidean(P)\n",
    "\n",
    "# ----------------------------- main ----------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    outdir = \"assets/costs\"\n",
    "    rgb = build_rgb_cost(bins=8)\n",
    "    lab = build_lab_cost(bins=8)\n",
    "    hcl = build_hcl_cost(bins=8, c_max=150.0)\n",
    "\n",
    "    check_and_save(rgb, os.path.join(outdir, \"cost_rgb512.npy\"))\n",
    "    check_and_save(lab, os.path.join(outdir, \"cost_lab514.npy\"))\n",
    "    check_and_save(hcl, os.path.join(outdir, \"cost_hcl514.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b18ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting POT\n",
      "  Downloading POT-0.9.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.12/dist-packages (from POT) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.12/dist-packages (from POT) (1.16.1)\n",
      "Downloading POT-0.9.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (901 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m901.7/901.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: POT\n",
      "Successfully installed POT-0.9.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d11f130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote assets/config/hist_config.json\n"
     ]
    }
   ],
   "source": [
    "import json, numpy as np, hashlib, os\n",
    "\n",
    "def edges(a,b,nb): return np.linspace(a,b,nb+1).tolist()\n",
    "def centers(a,b,nb): \n",
    "    e = np.linspace(a,b,nb+1); return ((e[:-1]+e[1:])/2).tolist()\n",
    "\n",
    "cfg = {\n",
    "  \"version\": \"v1-fast\",\n",
    "  \"bins\": 8,\n",
    "  \"rgb512\": {\n",
    "    \"axes\": {\"R\":{\"range\":[0,256],\"edges\":edges(0,256,8)},\n",
    "             \"G\":{\"range\":[0,256],\"edges\":edges(0,256,8)},\n",
    "             \"B\":{\"range\":[0,256],\"edges\":edges(0,256,8)}},\n",
    "    \"dim\": 512,\n",
    "    \"neutrals\": None\n",
    "  },\n",
    "  \"lab514\": {\n",
    "    # fast_lab_histogram: L∈[0,100]→L8, a,b shifted by +128 to [0,256]\n",
    "    \"axes\": {\"L8\":{\"range\":[0,256],\"edges\":edges(0,256,8)},\n",
    "             \"a8\":{\"range\":[0,256],\"edges\":edges(0,256,8)},\n",
    "             \"b8\":{\"range\":[0,256],\"edges\":edges(0,256,8)}},\n",
    "    \"neutrals\": {\"type\":\"black_white\",\n",
    "                 \"black\":{\"L<\":10, \"abs(a),abs(b)<\":2.0},\n",
    "                 \"white\":{\"L>\":90, \"abs(a),abs(b)<\":2.0}},\n",
    "    \"dim\": 514,\n",
    "    \"neutral_bin_indices\": {\"black\":512, \"white\":513}\n",
    "  },\n",
    "  \"hcl514\": {\n",
    "    # fast_hcl_histogram: L∈[0,100], C∈[0,150], H∈[0,360)\n",
    "    \"axes\": {\"L\":{\"range\":[0,100],\"edges\":edges(0,100,8)},\n",
    "             \"C\":{\"range\":[0,150],\"edges\":edges(0,150,8)},\n",
    "             \"H\":{\"range\":[0,360],\"edges\":edges(0,360,8)}},\n",
    "    \"neutrals\": {\"type\":\"black_white\",\n",
    "                 \"black\":{\"L<\":10, \"C<\":2.0},\n",
    "                 \"white\":{\"L>\":90, \"C<\":2.0}},\n",
    "    \"dim\": 514,\n",
    "    \"neutral_bin_indices\": {\"black\":512, \"white\":513}\n",
    "  }\n",
    "}\n",
    "\n",
    "os.makedirs(\"assets/config\", exist_ok=True)\n",
    "out = \"assets/config/hist_config.json\"\n",
    "with open(out,\"w\") as f: json.dump(cfg, f, indent=2)\n",
    "print(f\"Wrote {out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a106bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9ceba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f396d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8af4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec88ae36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca17223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import config  # ✅ will work if notebook is in same folder as config.py\n",
    "from data.dataset import UnifiedImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca2eb19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/thesis/AdImageNet/images/(300, 250)/ad_0...</td>\n",
       "      <td>ad_000001.jpg</td>\n",
       "      <td>$3\\nSTULZ\\nDifferential for 2nd Shift\\nManufac...</td>\n",
       "      <td>(300, 250)</td>\n",
       "      <td>300</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/thesis/AdImageNet/images/(300, 250)/ad_0...</td>\n",
       "      <td>ad_000009.jpg</td>\n",
       "      <td>VULTURE\\ninto\\nwith\\nSam Sanders\\nApple Podcasts</td>\n",
       "      <td>(300, 250)</td>\n",
       "      <td>300</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/thesis/AdImageNet/images/(300, 250)/ad_0...</td>\n",
       "      <td>ad_000017.jpg</td>\n",
       "      <td>smart\\ncare\\nO\\ndesign\\nbuild\\n&amp; install\\nrepa...</td>\n",
       "      <td>(300, 250)</td>\n",
       "      <td>300</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/thesis/AdImageNet/images/(300, 600)/ad_0...</td>\n",
       "      <td>ad_000020.jpg</td>\n",
       "      <td>TREE\\nSANTOR\\nMatch On!\\nThe Showstopper,\\nLuc...</td>\n",
       "      <td>(300, 600)</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/thesis/AdImageNet/images/(300, 250)/ad_0...</td>\n",
       "      <td>ad_000021.jpg</td>\n",
       "      <td>Local experts connecting\\ncustomers to YOUR bu...</td>\n",
       "      <td>(300, 250)</td>\n",
       "      <td>300</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path      file_name  \\\n",
       "0  /data/thesis/AdImageNet/images/(300, 250)/ad_0...  ad_000001.jpg   \n",
       "1  /data/thesis/AdImageNet/images/(300, 250)/ad_0...  ad_000009.jpg   \n",
       "2  /data/thesis/AdImageNet/images/(300, 250)/ad_0...  ad_000017.jpg   \n",
       "3  /data/thesis/AdImageNet/images/(300, 600)/ad_0...  ad_000020.jpg   \n",
       "4  /data/thesis/AdImageNet/images/(300, 250)/ad_0...  ad_000021.jpg   \n",
       "\n",
       "                                                text  dimensions  width  \\\n",
       "0  $3\\nSTULZ\\nDifferential for 2nd Shift\\nManufac...  (300, 250)    300   \n",
       "1   VULTURE\\ninto\\nwith\\nSam Sanders\\nApple Podcasts  (300, 250)    300   \n",
       "2  smart\\ncare\\nO\\ndesign\\nbuild\\n& install\\nrepa...  (300, 250)    300   \n",
       "3  TREE\\nSANTOR\\nMatch On!\\nThe Showstopper,\\nLuc...  (300, 600)    300   \n",
       "4  Local experts connecting\\ncustomers to YOUR bu...  (300, 250)    300   \n",
       "\n",
       "   height  \n",
       "0     250  \n",
       "1     250  \n",
       "2     250  \n",
       "3     600  \n",
       "4     250  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout_df = pd.read_csv(\"/data/thesis/adimagenet_manifest.csv\")\n",
    "layout_dataset = UnifiedImageDataset(layout_df, mode=\"file_df\", size=(224,224))\n",
    "layout_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc0c4eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved edge samples + meta.\n"
     ]
    }
   ],
   "source": [
    "import json, numpy as np, os\n",
    "from PIL import Image\n",
    "from degis.features.edge_maps import compute_edge_map_canny\n",
    "\n",
    "meta = {\"method\":\"canny\", \"low\":150, \"high\":200, \"resize\": [224,224]}\n",
    "os.makedirs(\"assets/edges\", exist_ok=True)\n",
    "\n",
    "samples = [(layout_df['file_path'][0],\"assets/edges/sample1.png\"),\n",
    "           (layout_df['file_path'][1],\"assets/edges/sample2.png\"),\n",
    "           (layout_df['file_path'][2],\"assets/edges/sample3.png\")]\n",
    "\n",
    "arr = []\n",
    "for src, dst in samples:\n",
    "    e = compute_edge_map_canny(Image.open(src).convert(\"RGB\"), (224,224))\n",
    "    arr.append(e.reshape(224,224))\n",
    "    Image.fromarray((arr[-1]*255).astype(np.uint8)).save(dst)\n",
    "\n",
    "np.save(\"assets/edges/samples.npy\", np.stack(arr,0))\n",
    "with open(\"assets/edges/meta.json\",\"w\") as f: json.dump(meta,f,indent=2)\n",
    "print(\"Saved edge samples + meta.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd85edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc4677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd4ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f30a3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote assets/clip/clip_meta.json\n"
     ]
    }
   ],
   "source": [
    "import json, torch\n",
    "clip_meta = {\n",
    "  \"open_clip_vit_h14\": {\n",
    "    \"source\": \"open_clip\",\n",
    "    \"model_name\": \"ViT-H-14\",\n",
    "    \"pretrained\": \"laion2b_s32b_b79k\",\n",
    "    \"embedding_dim\": 1024,\n",
    "    \"dtype_runtime\": \"fp16_on_cuda, cast_to_fp32_on_save\",\n",
    "    \"pooling\": \"model.encode_image() global projection\",\n",
    "    \"normalize\": \"none (downstream code may L2-normalize)\"\n",
    "  },\n",
    "  \"hf_clip_bigg14\": {\n",
    "    \"source\": \"transformers\",\n",
    "    \"model_id\": \"laion/CLIP-ViT-bigG-14-laion2B-39B-b160k\",\n",
    "    \"embedding_api\": \"CLIPVisionModelWithProjection.image_embeds\",\n",
    "    \"projection_dim\": 1024,\n",
    "    \"dtype_runtime\": \"fp16_on_cuda, cast_to_fp32_on_save\",\n",
    "    \"normalize\": \"L2 normalization applied (see code compute_clip_embedding_xl)\"\n",
    "  }\n",
    "}\n",
    "os.makedirs(\"assets/clip\", exist_ok=True)\n",
    "with open(\"assets/clip/clip_meta.json\",\"w\") as f: json.dump(clip_meta,f,indent=2)\n",
    "print(\"Wrote assets/clip/clip_meta.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9219f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f9486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a86aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66aee44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcc1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917b49db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Example (HCL with neutrals)\u001b[39;00m\n\u001b[32m     11\u001b[39m M = np.load(\u001b[33m\"\u001b[39m\u001b[33massets/costs/cost_hcl514.npy\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m emd = emd_hist(\u001b[43mh_gen\u001b[49m, h_ref, M)\n",
      "\u001b[31mNameError\u001b[39m: name 'h_gen' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ot  # pip install POT\n",
    "\n",
    "def emd_hist(p, q, M):\n",
    "    # p, q: 1D histograms (sum ~ 1), M: ground cost matrix (KxK)\n",
    "    p = p.astype(np.float32); q = q.astype(np.float32)\n",
    "    p = p / (p.sum() + 1e-8); q = q / (q.sum() + 1e-8)\n",
    "    return ot.emd2(p, q, M).item()  # scalar Earth Mover's Distance^2\n",
    "\n",
    "# Example (HCL with neutrals)\n",
    "M = np.load(\"assets/costs/cost_hcl514.npy\")\n",
    "emd = emd_hist(h_gen, h_ref, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374e7a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3336240,512) (512,3336240) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m os.path.exists(path), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m M = np.load(path)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m stats = \u001b[43mcheck_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m digest = sha256(path)\n\u001b[32m     72\u001b[39m row = {\n\u001b[32m     73\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: key,\n\u001b[32m     74\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: path,\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m: stats[\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     80\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mcheck_matrix\u001b[39m\u001b[34m(M, name)\u001b[39m\n\u001b[32m     47\u001b[39m n, m = M.shape\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# assert n == m, f\"{name}: not square ({n}x{m})\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: not symmetric\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     50\u001b[39m diag = np.diag(M)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m np.all(diag >= -\u001b[32m1e-7\u001b[39m), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: negative diagonal?\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/numpy/_core/numeric.py:2329\u001b[39m, in \u001b[36mallclose\u001b[39m\u001b[34m(a, b, rtol, atol, equal_nan)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mallclose\u001b[39m(a, b, rtol=\u001b[32m1.e-5\u001b[39m, atol=\u001b[32m1.e-8\u001b[39m, equal_nan=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   2245\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2246\u001b[39m \u001b[33;03m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[32m   2247\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2327\u001b[39m \n\u001b[32m   2328\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2329\u001b[39m     res = \u001b[38;5;28mall\u001b[39m(\u001b[43misclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m builtins.bool(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/numpy/_core/numeric.py:2447\u001b[39m, in \u001b[36misclose\u001b[39m\u001b[34m(a, b, rtol, atol, equal_nan)\u001b[39m\n\u001b[32m   2444\u001b[39m     y = \u001b[38;5;28mfloat\u001b[39m(y)\n\u001b[32m   2446\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m errstate(invalid=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2447\u001b[39m     result = (less_equal(\u001b[38;5;28mabs\u001b[39m(\u001b[43mx\u001b[49m\u001b[43m-\u001b[49m\u001b[43my\u001b[49m), atol + rtol * \u001b[38;5;28mabs\u001b[39m(y))\n\u001b[32m   2448\u001b[39m               & isfinite(y)\n\u001b[32m   2449\u001b[39m               | (x == y))\n\u001b[32m   2450\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m equal_nan:\n\u001b[32m   2451\u001b[39m         result |= isnan(x) & isnan(y)\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (3336240,512) (512,3336240) "
     ]
    }
   ],
   "source": [
    "# === verify_feature_assets.py ===\n",
    "# Purpose: load your precomputed EMD cost matrices, sanity-check them,\n",
    "# compute SHA256 checksums, and emit a tiny manifest (CSV + JSON) you can cite.\n",
    "\n",
    "import os, json, hashlib, csv\n",
    "import numpy as np\n",
    "\n",
    "# ---- EDIT THESE PATHS to your actual files ----\n",
    "ASSETS_DIR = \"/data/thesis/feature_assets\"   # where to write summaries/plots\n",
    "os.makedirs(ASSETS_DIR, exist_ok=True)\n",
    "\n",
    "COST_FILES = {\n",
    "    \"rgb512\":  config.COLOR_HIST_PATH_RGB,\n",
    "    \"lab514\":  config.COLOR_HIST_PATH_LAB_514,\n",
    "    \"hcl514\":  config.COLOR_HIST_PATH_HCL_514,\n",
    "}\n",
    "\n",
    "# Canonical histogram config you actually used (fast_* implementations)\n",
    "HIST_CONFIG = {\n",
    "    \"bins\": 8,\n",
    "    \"rgb\":  {\"ranges\": {\"R\": [0,256], \"G\": [0,256], \"B\": [0,256]}, \"neutral_bins\": 0},\n",
    "    \"lab\":  {\n",
    "        \"ranges\": {\"L\": [0,100], \"a\": \"rgb2lab(a)\", \"b\": \"rgb2lab(b)\"},\n",
    "        \"neutral_bins\": 2,\n",
    "        \"neutral_rule\": {\"black\": {\"L_lt\": 10, \"C_lt\": 2.0},\n",
    "                         \"white\": {\"L_gt\": 90, \"C_lt\": 2.0}},\n",
    "        \"dim\": 8**3 + 2\n",
    "    },\n",
    "    \"hcl\":  {\n",
    "        \"ranges\": {\"L\": [0,100], \"C\": [0,150.0], \"H\": [0,360]},\n",
    "        \"neutral_bins\": 2,\n",
    "        \"neutral_rule\": {\"black\": {\"L_lt\": 10, \"C_lt\": 2.0},\n",
    "                         \"white\": {\"L_gt\": 90, \"C_lt\": 2.0}},\n",
    "        \"dim\": 8**3 + 2\n",
    "    },\n",
    "}\n",
    "\n",
    "def sha256(path):\n",
    "    h = hashlib.sha256()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1024*1024), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def check_matrix(M, name):\n",
    "    assert isinstance(M, np.ndarray), f\"{name}: not an ndarray\"\n",
    "    n, m = M.shape\n",
    "    assert n == m, f\"{name}: not square ({n}x{m})\"\n",
    "    assert np.allclose(M, M.T, atol=1e-6), f\"{name}: not symmetric\"\n",
    "    diag = np.diag(M)\n",
    "    assert np.all(diag >= -1e-7), f\"{name}: negative diagonal?\"\n",
    "    assert np.allclose(diag, 0.0, atol=1e-6), f\"{name}: diagonal not ~0\"\n",
    "    assert np.nanmin(M) >= -1e-7, f\"{name}: negative entries?\"\n",
    "    return {\n",
    "        \"shape\": f\"{n}x{m}\",\n",
    "        \"min\": float(np.min(M)),\n",
    "        \"max\": float(np.max(M)),\n",
    "        \"mean\": float(np.mean(M)),\n",
    "        \"median\": float(np.median(M)),\n",
    "        \"std\": float(np.std(M)),\n",
    "    }\n",
    "\n",
    "# Load, validate, and record\n",
    "rows = []\n",
    "summary_json = {}\n",
    "\n",
    "for key, path in COST_FILES.items():\n",
    "    assert os.path.exists(path), f\"Missing: {path}\"\n",
    "    M = np.load(path)\n",
    "    stats = check_matrix(M, key)\n",
    "    digest = sha256(path)\n",
    "    row = {\n",
    "        \"name\": key,\n",
    "        \"path\": path,\n",
    "        \"shape\": stats[\"shape\"],\n",
    "        \"sha256\": digest,\n",
    "        \"min\": stats[\"min\"],\n",
    "        \"max\": stats[\"max\"],\n",
    "        \"mean\": stats[\"mean\"],\n",
    "    }\n",
    "    rows.append(row)\n",
    "    summary_json[key] = {**stats, \"sha256\": digest, \"path\": path}\n",
    "\n",
    "# Write CSV manifest\n",
    "csv_path = os.path.join(ASSETS_DIR, \"cost_matrices_manifest.csv\")\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "    w.writeheader(); w.writerows(rows)\n",
    "\n",
    "# Write JSON summary (plus your canonical histogram config)\n",
    "json_path = os.path.join(ASSETS_DIR, \"feature_assets_summary.json\")\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump({\"costs\": summary_json, \"hist_config\": HIST_CONFIG}, f, indent=2)\n",
    "\n",
    "print(f\"✔ Wrote:\\n- {csv_path}\\n- {json_path}\")\n",
    "\n",
    "# (Optional) save tiny downsampled heatmaps for the thesis (as sanity visuals)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    for key, path in COST_FILES.items():\n",
    "        M = np.load(path)\n",
    "        # downsample if >256 to keep figures light\n",
    "        step = max(1, M.shape[0] // 256)\n",
    "        Mv = M[::step, ::step]\n",
    "        plt.figure()\n",
    "        plt.imshow(Mv)\n",
    "        plt.title(f\"{key} ground-cost (downsample {step}x)\")\n",
    "        plt.colorbar()\n",
    "        out = os.path.join(ASSETS_DIR, f\"{key}_cost_heatmap.png\")\n",
    "        plt.savefig(out, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(f\"  • saved {out}\")\n",
    "except Exception as e:\n",
    "    print(f\"(skipped heatmaps: {e})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57561bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SYSTEM PROFILE ===\n",
      "Python: 3.12.3\n",
      "PyTorch: 2.8.0+cu128\n",
      "CPU cores: 256\n",
      "RAM: 540.8 GB, free 475.4 GB\n",
      "/data disk: total 1099.5 GB, free 249.7 GB\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 5090\n",
      "VRAM total: 33.7 GB\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "def print_system_profile():\n",
    "    print(\"=== SYSTEM PROFILE ===\")\n",
    "    print(\"Python:\", platform.python_version())\n",
    "    print(\"PyTorch:\", torch.__version__)\n",
    "    print(\"CPU cores:\", psutil.cpu_count(logical=True))\n",
    "    vm = psutil.virtual_memory()\n",
    "    print(f\"RAM: {vm.total/1e9:.1f} GB, free {vm.available/1e9:.1f} GB\")\n",
    "    \n",
    "    # Check if /data exists, otherwise check current directory\n",
    "    if os.path.exists(\"/data\"):\n",
    "        du = shutil.disk_usage(\"/data\")\n",
    "        print(f\"/data disk: total {du.total/1e9:.1f} GB, free {du.free/1e9:.1f} GB\")\n",
    "    else:\n",
    "        du = shutil.disk_usage(\".\")\n",
    "        print(f\"Current disk: total {du.total/1e9:.1f} GB, free {du.free/1e9:.1f} GB\")\n",
    "    \n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        i = torch.cuda.current_device()\n",
    "        print(\"GPU:\", torch.cuda.get_device_name(i))\n",
    "        print(f\"VRAM total: {torch.cuda.get_device_properties(i).total_memory/1e9:.1f} GB\")\n",
    "    print(\"======================\")\n",
    "\n",
    "print_system_profile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39699604",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "embeddings_size = \"base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c19251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'coco'\n",
    "name = 'laion_5m'\n",
    "# name = 'adimagenet'\n",
    "csv_path = f\"/data/thesis/{name}_manifest.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9c59c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 3336240 images\n",
      "Columns: ['id', 'url', 'caption', 'aesthetic', 'local_path']\n",
      "(3336240, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>caption</th>\n",
       "      <th>aesthetic</th>\n",
       "      <th>local_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6744</td>\n",
       "      <td>https://t0.gstatic.com/images?q=tbn:ANd9GcQM-D...</td>\n",
       "      <td>Wrought Iron King Headboard And Footboard by B...</td>\n",
       "      <td>7.297200</td>\n",
       "      <td>/data/thesis/laion_5m_images/0006744.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5801</td>\n",
       "      <td>https://i.dailymail.co.uk/1s/2020/03/24/16/263...</td>\n",
       "      <td>Kayley and Ryan said they were determined to '...</td>\n",
       "      <td>7.451863</td>\n",
       "      <td>/data/thesis/laion_5m_images/0005801.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8959</td>\n",
       "      <td>https://cdn.shopify.com/s/files/1/2068/6307/pr...</td>\n",
       "      <td>Pink Minnie Mouse suspender dress</td>\n",
       "      <td>7.530277</td>\n",
       "      <td>/data/thesis/laion_5m_images/0008959.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9283</td>\n",
       "      <td>http://t0.gstatic.com/images?q=tbn:ANd9GcSxmV1...</td>\n",
       "      <td>Xmas Home Decorating Ideas by Best 25 Christma...</td>\n",
       "      <td>7.742550</td>\n",
       "      <td>/data/thesis/laion_5m_images/0009283.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2750</td>\n",
       "      <td>https://cdn.smokymountains.com/vacation-rental...</td>\n",
       "      <td>Photo of a Gatlinburg Cabin named The Blue Spr...</td>\n",
       "      <td>7.035913</td>\n",
       "      <td>/data/thesis/laion_5m_images/0002750.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                                url  \\\n",
       "0  6744  https://t0.gstatic.com/images?q=tbn:ANd9GcQM-D...   \n",
       "1  5801  https://i.dailymail.co.uk/1s/2020/03/24/16/263...   \n",
       "2  8959  https://cdn.shopify.com/s/files/1/2068/6307/pr...   \n",
       "3  9283  http://t0.gstatic.com/images?q=tbn:ANd9GcSxmV1...   \n",
       "4  2750  https://cdn.smokymountains.com/vacation-rental...   \n",
       "\n",
       "                                             caption  aesthetic  \\\n",
       "0  Wrought Iron King Headboard And Footboard by B...   7.297200   \n",
       "1  Kayley and Ryan said they were determined to '...   7.451863   \n",
       "2                  Pink Minnie Mouse suspender dress   7.530277   \n",
       "3  Xmas Home Decorating Ideas by Best 25 Christma...   7.742550   \n",
       "4  Photo of a Gatlinburg Cabin named The Blue Spr...   7.035913   \n",
       "\n",
       "                                 local_path  \n",
       "0  /data/thesis/laion_5m_images/0006744.jpg  \n",
       "1  /data/thesis/laion_5m_images/0005801.jpg  \n",
       "2  /data/thesis/laion_5m_images/0008959.jpg  \n",
       "3  /data/thesis/laion_5m_images/0009283.jpg  \n",
       "4  /data/thesis/laion_5m_images/0002750.jpg  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Dataset loaded: {len(df)} images\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "939bbf75",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mtimed_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m  \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msdxl_1024_ip0.6\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m  \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_ip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mip_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcn_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     43\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtimed_generate\u001b[39m\u001b[34m(run_name, gen_fn, resolution, steps, cfg, attn_ip, ip_scale, text_scale, cn_scale, precision)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m     10\u001b[39m     torch.cuda.synchronize()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m _ = \u001b[43mgen_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# measure\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(warmup)\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[32m     40\u001b[39m timed_generate(\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33msdxl_1024_ip0.6\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m warmup=\u001b[38;5;28;01mFalse\u001b[39;00m: \u001b[43mrun_pipeline\u001b[49m(warmup),\n\u001b[32m     42\u001b[39m   resolution=\u001b[32m1024\u001b[39m, steps=\u001b[32m50\u001b[39m, cfg=\u001b[32m7.0\u001b[39m, attn_ip=\u001b[32m0.6\u001b[39m, ip_scale=\u001b[32m0.4\u001b[39m, text_scale=\u001b[32m1.1\u001b[39m, cn_scale=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'run_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# efficiency_logger.py\n",
    "import time, csv, torch\n",
    "from pathlib import Path\n",
    "\n",
    "def timed_generate(run_name, gen_fn, *, resolution, steps, cfg,\n",
    "                   attn_ip, ip_scale, text_scale, cn_scale=None,\n",
    "                   precision=\"fp16\"):\n",
    "    # warmup\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    _ = gen_fn(warmup=True)\n",
    "\n",
    "    # measure\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "    t0 = time.perf_counter()\n",
    "    _ = gen_fn()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "        peak = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "    else:\n",
    "        peak = 0.0\n",
    "    dt_ms = (time.perf_counter() - t0) * 1000\n",
    "\n",
    "    row = dict(\n",
    "        run=run_name, res=resolution, steps=steps, cfg=cfg,\n",
    "        attn_ip=attn_ip, ip_scale=ip_scale, text_scale=text_scale,\n",
    "        cn_scale=cn_scale if cn_scale is not None else \"\",\n",
    "        latency_ms=round(dt_ms, 1), peak_vram_mb=int(peak), precision=precision\n",
    "    )\n",
    "    out = Path(\"efficiency_logs.csv\"); new = not out.exists()\n",
    "    with out.open(\"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=row.keys())\n",
    "        if new: w.writeheader()\n",
    "        w.writerow(row)\n",
    "    return row\n",
    "\n",
    "# Example:\n",
    "timed_generate(\n",
    "  \"sdxl_1024_ip0.6\", lambda warmup=False: run_pipeline(warmup),\n",
    "  resolution=1024, steps=50, cfg=7.0, attn_ip=0.6, ip_scale=0.4, text_scale=1.1, cn_scale=\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db6d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed88c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
