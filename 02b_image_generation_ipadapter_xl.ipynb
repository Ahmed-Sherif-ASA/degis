{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Generation with IP-Adapter XL (SDXL)\n",
        "\n",
        "This notebook demonstrates how to use the DEGIS package to:\n",
        "1. Load trained color head models\n",
        "2. Set up IP-Adapter XL with ControlNet for high-quality image generation\n",
        "3. Generate images using color and layout control with SDXL\n",
        "\n",
        "Based on the ablation notebook but using IP-Adapter XL for higher quality results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ DEGIS environment is active\n",
            "üêç Python: /data/degis/degis-env/bin/python\n",
            "‚úÖ DEGIS package is available\n",
            "\n",
            "üöÄ Ready to start image generation!\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT CHECK - Run this cell first!\n",
        "# =============================================================================\n",
        "# This cell verifies that the DEGIS environment is properly set up\n",
        "# Make sure you've run ./setup_server_fixed.sh first!\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Check if we're in the right environment\n",
        "if 'degis-env' in sys.executable:\n",
        "    print(\"‚úÖ DEGIS environment is active\")\n",
        "    print(f\"üêç Python: {sys.executable}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Warning: DEGIS environment not detected\")\n",
        "    print(\"   Please run: ./setup_server_fixed.sh\")\n",
        "    print(\"   Then activate: source degis-env/bin/activate\")\n",
        "\n",
        "# Check if DEGIS package is available\n",
        "try:\n",
        "    import degis\n",
        "    print(\"‚úÖ DEGIS package is available\")\n",
        "except ImportError:\n",
        "    print(\"‚ùå DEGIS package not found\")\n",
        "    print(\"   Please run: ./setup_server_fixed.sh\")\n",
        "\n",
        "print(\"\\nüöÄ Ready to start image generation!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports successful!\n",
            "üé® Ready for high-quality image generation with IP-Adapter XL!\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# IMPORTS - Run this after the setup cell above\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Import DEGIS package components\n",
        "import degis\n",
        "from degis.core.generation import IPAdapterXLGenerator, load_trained_color_head, get_color_embedding\n",
        "from degis.core.visualization import plot_color_palette, display_images_grid\n",
        "from degis.utils import create_control_edge_pil\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(\"üé® Ready for high-quality image generation with IP-Adapter XL!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from IPython.display import display\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Import the DEGIS package\n",
        "import degis\n",
        "from degis.data.dataset import UnifiedImageDataset\n",
        "# from degis.config import csv_path, embeddings_path, colour_path, precomputed_adimagenet_edge_maps_path\n",
        "\n",
        "# Import IP-Adapter XL with DEGIS patches\n",
        "import ip_adapter_patch  # This applies the DEGIS monkey patches\n",
        "import ip_adapter\n",
        "from ip_adapter import IPAdapterXL\n",
        "from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline\n",
        "from degis.features.color_histograms import compute_color_histogram\n",
        "from degis.features.color_histograms import compute_lab_histogram\n",
        "import geomloss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Data and Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_path = \"/data/thesis/laion_5m_manifest.csv\"\n",
        "embeddings_path = \"/data/thesis/models/hf_xl_laion_5m_embeddings.npy\" # || YOUR_CUSTOM_PATH\n",
        "colour_path = \"/data/thesis/data/laion_5m_color_histograms_lab_514.npy\" # options: COLOR_HIST_PATH_LAB_514 || COLOR_HIST_PATH_RGB || YOUR_CUSTOM_PATH\n",
        "colour_head_checkpoint_path = \"/data/degis/evaluation_runs/laion_5m_xl_lab514_tk20_b4096/best_color_head_tmp.pth\" # || YOUR_CUSTOM_PATH\n",
        "precomputed_adimagenet_edge_maps_path = \"/data/thesis/data/adimagenet_edge_maps.npy\" # || YOUR_CUSTOM_PATH\n",
        "\n",
        "\n",
        "# ip_ckpt = \"/data/thesis/models/ip-adapter_sd15.bin\"\n",
        "image_encoder_path = \"laion/CLIP-ViT-bigG-14-laion2B-39B-b160k\"\n",
        "controlnet_id = \"diffusers/controlnet-canny-sdxl-1.0\"\n",
        "# stable_diffusion_model_id = \"runwayml/stable-diffusion-v1-5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded embeddings: (3336240, 1280)\n",
            "Loaded histograms: (3336240, 514)\n",
            "Loaded edge maps: (2080, 50176)\n",
            "‚úì Color head loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "df = pd.read_csv(csv_path)\n",
        "colour_dataset = UnifiedImageDataset(\n",
        "    df.rename(columns={\"local_path\": \"file_path\"}),\n",
        "    mode=\"file_df\",\n",
        "    size=(224, 224),\n",
        "    subset_ratio=1.0\n",
        ")\n",
        "\n",
        "# Load precomputed data\n",
        "embeddings = np.load(embeddings_path, mmap_mode=\"r\").astype(np.float32, copy=False)\n",
        "histograms = np.load(colour_path, mmap_mode=\"r\").astype(np.float32, copy=False)\n",
        "edge_maps = np.load(precomputed_adimagenet_edge_maps_path, mmap_mode=\"r\")\n",
        "\n",
        "print(f\"Loaded embeddings: {embeddings.shape}\")\n",
        "print(f\"Loaded histograms: {histograms.shape}\")\n",
        "print(f\"Loaded edge maps: {edge_maps.shape}\")\n",
        "\n",
        "# Load trained color head\n",
        "color_head = degis.load_trained_color_head(\n",
        "    checkpoint_path=colour_head_checkpoint_path,\n",
        "    clip_dim=embeddings.shape[1],\n",
        "    hist_dim=histograms.shape[1],\n",
        "    device=device\n",
        ")\n",
        "print(\"‚úì Color head loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup IP-Adapter XL Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cache directory: /data/hf-cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Keyword arguments {'safety_checker': None} are not expected by StableDiffusionXLControlNetPipeline and will be ignored.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d82f351ce0a42c7bf536b36f5ca2ee7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IP-Adapter sdxl checkpoint not found at h94/IP-Adapter\n",
            "Downloading IP-Adapter sdxl checkpoint...\n",
            "‚úì Downloaded IP-Adapter sdxl checkpoint\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a199662c083240559d823b6e73ba8157",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì IP-Adapter XL pipeline setup complete\n"
          ]
        }
      ],
      "source": [
        "# Setup cache directory\n",
        "HF_CACHE = \"/data/hf-cache\" if os.path.exists(\"/data\") else \"./hf-cache\"\n",
        "os.makedirs(HF_CACHE, exist_ok=True)\n",
        "\n",
        "os.environ[\"HF_HOME\"] = HF_CACHE\n",
        "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = os.path.join(HF_CACHE, \"hub\")\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = os.path.join(HF_CACHE, \"transformers\")\n",
        "os.environ[\"DIFFUSERS_CACHE\"] = os.path.join(HF_CACHE, \"diffusers\")\n",
        "os.environ[\"TORCH_HOME\"] = os.path.join(HF_CACHE, \"torch\")\n",
        "\n",
        "print(f\"Using cache directory: {HF_CACHE}\")\n",
        "\n",
        "# Create IP-Adapter XL generator\n",
        "generator = degis.IPAdapterXLGenerator(device=device)\n",
        "\n",
        "# Setup the pipeline\n",
        "generator.setup_pipeline(\n",
        "    model_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    controlnet_id=controlnet_id,\n",
        "    ip_ckpt=None,  # Update path as needed\n",
        "    image_encoder_path=image_encoder_path,\n",
        "    cache_dir=HF_CACHE,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "print(\"‚úì IP-Adapter XL pipeline setup complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Image Generation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch, gc\n",
        "\n",
        "# def generate_from_dataset_id_xl(\n",
        "#     colour_index: int,\n",
        "#     layout_index: int,\n",
        "#     prompt: str = \"a cat playing with a ball\",\n",
        "#     guidance_scale: float = 6.5,\n",
        "#     steps: int = 40,\n",
        "#     controlnet_conditioning_scale: float = 0.8,\n",
        "#     num_samples: int = 1,\n",
        "#     attn_ip_scale: float = 0.8,\n",
        "#     text_token_scale: float = 1.0,\n",
        "#     ip_token_scale: float = None,\n",
        "#     ip_uncond_scale: float = 0.0,\n",
        "#     zero_ip_in_uncond: bool = True,\n",
        "# ):\n",
        "#     \"\"\"Generate images using IP-Adapter XL with advanced controls.\"\"\"\n",
        "#     import torch, gc\n",
        "#     gc.collect()\n",
        "#     torch.cuda.empty_cache()\n",
        "#     # Get original image for display\n",
        "#     img_t, _ = colour_dataset[colour_index]\n",
        "#     pil_img = transforms.ToPILImage()(img_t)\n",
        "    \n",
        "#     # Get CLIP embedding and compute color embedding\n",
        "#     z_clip = torch.as_tensor(embeddings[colour_index], dtype=torch.float32, device=device).unsqueeze(0)\n",
        "#     color_embedding = degis.get_color_embedding(color_head, z_clip)\n",
        "    \n",
        "#     # Create control image from edge data\n",
        "#     control_image = degis.create_edge_control_image(edge_maps[layout_index], size=512)\n",
        "    \n",
        "#     # Generate images with IP-Adapter XL\n",
        "#     images = generator.generate(\n",
        "#         color_embedding=color_embedding,\n",
        "#         control_image=control_image,\n",
        "#         prompt=prompt,\n",
        "#         # negative_prompt=(\n",
        "#         #     \"monochrome, lowres, bad anatomy, worst quality, low quality, blurry, \"\n",
        "#         #     \"sketch, cartoon, drawing, anime:1.4, comic, illustration, posterized, \"\n",
        "#         #     \"mosaic, stained glass, abstract, surreal, psychedelic, trippy, texture artifact, \"\n",
        "#         #     \"embroidery, knitted, painting, oversaturated, unrealistic, bad shading\"\n",
        "#         # ),\n",
        "#         num_samples=num_samples,\n",
        "#         guidance_scale=guidance_scale,\n",
        "#         num_inference_steps=steps,\n",
        "#         controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
        "#         # IP-Adapter XL specific parameters\n",
        "#         attn_ip_scale=attn_ip_scale,\n",
        "#         text_token_scale=text_token_scale,\n",
        "#         ip_token_scale=ip_token_scale,\n",
        "#         ip_uncond_scale=ip_uncond_scale,\n",
        "#         zero_ip_in_uncond=zero_ip_in_uncond,\n",
        "#     )\n",
        "    \n",
        "#     # Display results\n",
        "#     comparison = degis.display_comparison_grid(\n",
        "#         original=pil_img,\n",
        "#         control=control_image,\n",
        "#         generated=images,\n",
        "#         cols=3\n",
        "#     )\n",
        "#     display(comparison)\n",
        "    \n",
        "#     return images\n",
        "\n",
        "# print(\"‚úì IP-Adapter XL generation function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Generate High-Quality Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # ==== Aligned GT vs Pred top-20 + IMAGE (first 10) ====\n",
        "# import os, numpy as np, torch, matplotlib.pyplot as plt, pandas as pd\n",
        "# from skimage.color import lab2rgb\n",
        "# BINS      = 8\n",
        "# TOP_K     = 14\n",
        "# SPACE = \"lab\"\n",
        "# hist = histograms\n",
        "# emb = embeddings\n",
        "# HIST_KIND = \"lab514\"   # \"rgb512\" | \"lab514\" | \"hcl514\"\n",
        "# sinkhorn = geomloss.SamplesLoss(\"sinkhorn\", p=2, blur=0.05, backend=\"tensorized\")\n",
        "# def _top_palette(vec, bins=BINS, top_k=TOP_K, space=SPACE, c_max=150.0):\n",
        "#     v = vec.detach().cpu().numpy() if isinstance(vec, torch.Tensor) else np.asarray(vec)\n",
        "#     core = v[:bins**3]  # ignore the last 2 BW slots for palette picking\n",
        "#     idxs = np.argsort(core)[-top_k:][::-1]\n",
        "#     cols = []\n",
        "#     if space == \"rgb\":\n",
        "#         for flat in idxs:\n",
        "#             ri = flat // (bins*bins); gi = (flat // bins) % bins; bi = flat % bins\n",
        "#             cols.append(((ri+0.5)/bins, (gi+0.5)/bins, (bi+0.5)/bins))\n",
        "#     elif space == \"lab\":\n",
        "#         for flat in idxs:\n",
        "#             Li = flat // (bins*bins); ai = (flat // bins) % bins; bi = flat % bins\n",
        "#             L = (Li+0.5)/bins*100.0\n",
        "#             a = (ai+0.5)/bins*255.0 - 128.0\n",
        "#             b = (bi+0.5)/bins*255.0 - 128.0\n",
        "#             cols.append(tuple(lab2rgb(np.array([[[L,a,b]]]))[0,0]))\n",
        "#     elif space == \"hcl\":\n",
        "#         for flat in idxs:\n",
        "#             Li = flat // (bins*bins); Ci = (flat // bins) % bins; Hi = flat % bins\n",
        "#             L = (Li+0.5)/bins*100.0\n",
        "#             C = (Ci+0.5)/bins*c_max\n",
        "#             H = (Hi+0.5)/bins*360.0\n",
        "#             a = C*np.cos(np.deg2rad(H)); b = C*np.sin(np.deg2rad(H))\n",
        "#             cols.append(tuple(lab2rgb(np.array([[[L,a,b]]]))[0,0]))\n",
        "#     else:\n",
        "#         raise ValueError(\"space must be 'rgb' | 'lab' | 'hcl'\")\n",
        "#     return cols, core[idxs]\n",
        "\n",
        "# def _plot_palette(ax, colors, values, title):\n",
        "#     for i, (c, v) in enumerate(zip(colors, values)):\n",
        "#         ax.add_patch(plt.Rectangle((i, 0), 1, 1, color=c))\n",
        "#         ax.text(i+0.5, -0.08, f\"{v:.3f}\", ha=\"center\", va=\"top\", fontsize=7)\n",
        "#     ax.set_xlim(0, len(colors)); ax.set_ylim(0,1); ax.axis(\"off\")\n",
        "#     ax.set_title(title, fontsize=12)\n",
        "\n",
        "# def show_aligned(i, dataset):\n",
        "#     # image from the SAME dataset (guarantees correct ordering)\n",
        "#     img_t, _ = dataset[i]                    # [3,224,224] float [0,1]\n",
        "#     img_np   = img_t.permute(1,2,0).numpy()  # HWC\n",
        "\n",
        "#     # GT and Pred from aligned arrays / model\n",
        "#     h_gt = torch.from_numpy(hist[i]).to(device)\n",
        "#     z    = torch.from_numpy(emb[i]).to(device).unsqueeze(0)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         _, p, _ = color_head(z)\n",
        "#         p = p.squeeze(0)\n",
        "#         p = p / (p.sum() + 1e-8)\n",
        "#         g = h_gt / (h_gt.sum() + 1e-8)\n",
        "#         l1  = torch.sum(torch.abs(p-g)).item()\n",
        "#         cos = torch.nn.functional.cosine_similarity(p, g, dim=0).item()\n",
        "#         emd = sinkhorn(p.unsqueeze(0), g.unsqueeze(0)).item() if sinkhorn is not None else None\n",
        "\n",
        "#     gt_cols, gt_vals = _top_palette(g)\n",
        "#     pr_cols, pr_vals = _top_palette(p)\n",
        "\n",
        "#     # draw\n",
        "#     fig, axes = plt.subplots(2, 2, figsize=(14, 5), gridspec_kw={\"height_ratios\":[2,1]})\n",
        "#     axes[0,0].imshow(img_np); axes[0,0].axis(\"off\")\n",
        "#     basename = os.path.basename(str(dataset.df.iloc[i][\"file_path\"]))\n",
        "#     # axes[0,0].set_title(f\"idx={i}  ({basename})\")\n",
        "#     axes[0,0].set_title(f\"EMD={emd:.4f}\")\n",
        "#     # if emd is not None: txt += f\"\\nEMD = {emd:.4f}\"\n",
        "\n",
        "#     axes[0,1].axis(\"off\")\n",
        "#     txt = f\"Histogram kind: {HIST_KIND}\\nL1 = {l1:.4f}\\nCosine = {cos:.4f}\"\n",
        "#     if emd is not None: txt += f\"\\nEMD = {emd:.4f}\"\n",
        "#     axes[0,1].text(0.02, 0.85, txt, fontsize=12, va=\"top\")\n",
        "\n",
        "#     _plot_palette(axes[1,0], pr_cols, pr_vals, f\"Pred top-bins\")\n",
        "#     _plot_palette(axes[1,1], gt_cols, gt_vals, f\"GT top-{TOP_K}\")\n",
        "#     plt.tight_layout(); plt.show()\n",
        "\n",
        "# for i in range(100000, 100020):\n",
        "#     show_aligned(i, colour_dataset)\n",
        "# # for i in range(1000, 1010):\n",
        "# #     show_aligned(i, colour_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from degis.core import generate_from_dataset_id_xl_with_emd\n",
        "\n",
        "\n",
        "images, best_emd, attempts = generate_from_dataset_id_xl_with_emd(\n",
        "    colour_index=1008,\n",
        "    layout_index=33,\n",
        "    prompt=\"identical hoodies, advertisement style, professional photography\",\n",
        "    target_emd_threshold=0.2,\n",
        "    max_attempts=20,\n",
        "    top_k=20,\n",
        "    guidance_scale=15,\n",
        "    steps=50,\n",
        "    controlnet_conditioning_scale=0.4,\n",
        "    num_samples=1,\n",
        "    attn_ip_scale=0.6,\n",
        "    text_token_scale=1.1,\n",
        "    ip_token_scale=None,\n",
        "    ip_uncond_scale=0.0,\n",
        "    zero_ip_in_uncond=True,\n",
        "    verbose=True,\n",
        "    # Required dependencies (pass from your notebook context)\n",
        "    generator=generator,\n",
        "    colour_dataset=colour_dataset,\n",
        "    embeddings=embeddings,\n",
        "    histograms=histograms,\n",
        "    edge_maps=edge_maps,\n",
        "    color_head=color_head,\n",
        "    device=device,\n",
        "    transforms=transforms\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating images with IP-Adapter XL (SDXL)...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "generator is required",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating images with IP-Adapter XL (SDXL)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Example 1: Cat with ball (high quality)\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# images1 = generate_from_dataset_id_xl(\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#     colour_index=1000,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Example 2: Dog on hoodie (artistic style)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mgenerate_from_dataset_id_xl_with_emd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolour_index\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1008\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayout_index\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m33\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43midentical hoodies, advertisement style, professional photography\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontrolnet_conditioning_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_ip_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_token_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mip_token_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mip_uncond_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mzero_ip_in_uncond\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# # Example 2: Dog on hoodie (artistic style)\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# generate_from_dataset_id_xl(\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m#     colour_index=1008,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[38;5;66;03m#     zero_ip_in_uncond=True,\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úì High-quality image generation complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/data/degis/degis/core/emd_generation.py:191\u001b[39m, in \u001b[36mgenerate_from_dataset_id_xl_with_emd\u001b[39m\u001b[34m(colour_index, layout_index, prompt, target_emd_threshold, max_attempts, top_k, guidance_scale, steps, controlnet_conditioning_scale, num_samples, attn_ip_scale, text_token_scale, ip_token_scale, ip_uncond_scale, zero_ip_in_uncond, color_space, blur, verbose, generator, colour_dataset, embeddings, histograms, edge_maps, color_head, device, transforms)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# Validate required dependencies\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m generator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator is required\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m colour_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcolour_dataset is required\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mValueError\u001b[39m: generator is required"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Generate high-quality images with IP-Adapter XL\n",
        "print(\"Generating images with IP-Adapter XL (SDXL)...\")\n",
        "\n",
        "# Example 1: Cat with ball (high quality)\n",
        "# images1 = generate_from_dataset_id_xl(\n",
        "#     colour_index=1000,\n",
        "#     layout_index=33,\n",
        "#     prompt=\"a cat playing with a ball, high quality, detailed\",\n",
        "#     guidance_scale=6.5,\n",
        "#     steps=40,\n",
        "#     controlnet_conditioning_scale=0.8,\n",
        "#     num_samples=1,\n",
        "#     attn_ip_scale=0.8,\n",
        "#     text_token_scale=1.0,\n",
        "#     ip_token_scale=0.5,\n",
        "#     ip_uncond_scale=0.0,\n",
        "#     zero_ip_in_uncond=True,\n",
        "# )\n",
        "\n",
        "# Example 2: Dog on hoodie (artistic style)\n",
        "generate_from_dataset_id_xl_with_emd(\n",
        "    colour_index=1008,\n",
        "    layout_index=33,\n",
        "    prompt=\"identical hoodies, advertisement style, professional photography\",\n",
        "    guidance_scale=15,\n",
        "    steps=50,\n",
        "    controlnet_conditioning_scale=0.4,\n",
        "    num_samples=1,\n",
        "    attn_ip_scale=0.6,\n",
        "    text_token_scale=1.5,\n",
        "    ip_token_scale=0.4,\n",
        "    ip_uncond_scale=0.0,\n",
        "    zero_ip_in_uncond=False,\n",
        ")\n",
        "\n",
        "\n",
        "# # Example 2: Dog on hoodie (artistic style)\n",
        "# generate_from_dataset_id_xl(\n",
        "#     colour_index=1008,\n",
        "#     layout_index=33,\n",
        "#     prompt=\"a car, advertisement style, professional photography\",\n",
        "#     guidance_scale=15,\n",
        "#     steps=50,\n",
        "#     controlnet_conditioning_scale=0.4,\n",
        "#     num_samples=1,\n",
        "#     attn_ip_scale=0.6,\n",
        "#     text_token_scale=1.5,\n",
        "#     ip_token_scale=0.4,\n",
        "#     ip_uncond_scale=0.0,\n",
        "#     zero_ip_in_uncond=False,\n",
        "# )\n",
        "\n",
        "# # Example 3: Creative composition\n",
        "# images3 = generate_from_dataset_id_xl(\n",
        "#     colour_index=1003,\n",
        "#     layout_index=33,\n",
        "#     prompt=\"A cat on the hoodie, digital art, vibrant colors, masterpiece\",\n",
        "#     guidance_scale=8.0,\n",
        "#     steps=60,\n",
        "#     controlnet_conditioning_scale=0.7,\n",
        "#     num_samples=1,\n",
        "#     attn_ip_scale=0.7,\n",
        "#     text_token_scale=1.2,\n",
        "#     ip_token_scale=0.6,\n",
        "#     ip_uncond_scale=0.0,\n",
        "#     zero_ip_in_uncond=True,\n",
        "# )\n",
        "\n",
        "print(\"‚úì High-quality image generation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def calculate_emd_distance_topk(hist1: np.ndarray, hist2: np.ndarray, top_k: int = 20, blur: float = 0.01) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Earth Mover's Distance between top-k histogram values using Sinkhorn algorithm.\n",
        "    \n",
        "    Args:\n",
        "        hist1: First histogram (normalized)\n",
        "        hist2: Second histogram (normalized)\n",
        "        top_k: Number of top histogram values to consider\n",
        "        blur: Blur parameter for Sinkhorn algorithm\n",
        "        \n",
        "    Returns:\n",
        "        EMD distance value\n",
        "    \"\"\"\n",
        "    # Get top-k indices for both histograms\n",
        "    top_indices_1 = np.argsort(hist1)[-top_k:]\n",
        "    top_indices_2 = np.argsort(hist2)[-top_k:]\n",
        "    \n",
        "    # Get unique indices (union of both top-k sets)\n",
        "    unique_indices = np.union1d(top_indices_1, top_indices_2)\n",
        "    \n",
        "    # Extract top-k values and normalize\n",
        "    h1_topk = hist1[unique_indices]\n",
        "    h2_topk = hist2[unique_indices]\n",
        "    \n",
        "    # Normalize to sum to 1\n",
        "    h1_topk = h1_topk / (h1_topk.sum() + 1e-8)\n",
        "    h2_topk = h2_topk / (h2_topk.sum() + 1e-8)\n",
        "    \n",
        "    # Convert to torch tensors and add batch dimension\n",
        "    h1 = torch.tensor(h1_topk, dtype=torch.float32).unsqueeze(0)\n",
        "    h2 = torch.tensor(h2_topk, dtype=torch.float32).unsqueeze(0)\n",
        "    \n",
        "    # Calculate EMD using Sinkhorn\n",
        "    loss = geomloss.SamplesLoss(\"sinkhorn\", p=2, blur=blur, backend=\"tensorized\")\n",
        "    emd = loss(h1, h2).item()\n",
        "    \n",
        "    return emd\n",
        "\n",
        "def generate_from_dataset_id_xl_with_emd(\n",
        "    colour_index: int,\n",
        "    layout_index: int,\n",
        "    prompt: str = \"a cat playing with a ball\",\n",
        "    target_emd_threshold: float = 0.1,\n",
        "    max_attempts: int = 20,\n",
        "    top_k: int = 20,  # New parameter for top-k EMD\n",
        "    guidance_scale: float = 6.5,\n",
        "    steps: int = 40,\n",
        "    controlnet_conditioning_scale: float = 0.8,\n",
        "    num_samples: int = 1,\n",
        "    attn_ip_scale: float = 0.8,\n",
        "    text_token_scale: float = 1.0,\n",
        "    ip_token_scale: float = None,\n",
        "    ip_uncond_scale: float = 0.0,\n",
        "    zero_ip_in_uncond: bool = True,\n",
        "):\n",
        "    \"\"\"Generate images using IP-Adapter XL with EMD constraint on top-k histogram values.\"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    # Get original image for display\n",
        "    img_t, _ = colour_dataset[colour_index]\n",
        "    pil_img = transforms.ToPILImage()(img_t)\n",
        "    \n",
        "    # Get CLIP embedding and compute color embedding\n",
        "    z_clip = torch.as_tensor(embeddings[colour_index], dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    color_embedding = degis.get_color_embedding(color_head, z_clip)\n",
        "    \n",
        "    # Get original histogram for EMD comparison\n",
        "    original_histogram = histograms[colour_index]\n",
        "    \n",
        "    # Create control image from edge data\n",
        "    control_image = degis.create_edge_control_image(edge_maps[layout_index], size=512)\n",
        "    \n",
        "    # EMD-constrained generation\n",
        "    best_images = None\n",
        "    best_emd = float('inf')\n",
        "    attempts_made = 0\n",
        "    \n",
        "    print(f\"Generating with EMD constraint (target: {target_emd_threshold:.3f})\")\n",
        "    print(f\"Using prompt: '{prompt}'\")\n",
        "    print(f\"Max attempts: {max_attempts}\")\n",
        "    print(f\"EMD calculation: top-{top_k} histogram values\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    for attempt in range(max_attempts):\n",
        "        # Generate images with IP-Adapter XL\n",
        "        images = generator.generate(\n",
        "            color_embedding=color_embedding,\n",
        "            control_image=control_image,\n",
        "            prompt=prompt,\n",
        "            negative_prompt=(\n",
        "                \"monochrome, lowres, bad anatomy, worst quality, low quality, blurry, \"\n",
        "                \"sketch, cartoon, drawing, anime:1.4, comic, illustration, posterized, \"\n",
        "                \"mosaic, stained glass, abstract, surreal, psychedelic, trippy, texture artifact, \"\n",
        "                \"embroidery, knitted, painting, oversaturated, unrealistic, bad shading\"\n",
        "            ),\n",
        "            num_samples=num_samples,\n",
        "            guidance_scale=guidance_scale,\n",
        "            num_inference_steps=steps,\n",
        "            controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
        "            # IP-Adapter XL specific parameters\n",
        "            attn_ip_scale=attn_ip_scale,\n",
        "            text_token_scale=text_token_scale,\n",
        "            ip_token_scale=ip_token_scale,\n",
        "            ip_uncond_scale=ip_uncond_scale,\n",
        "            zero_ip_in_uncond=zero_ip_in_uncond,\n",
        "        )\n",
        "        \n",
        "        # Calculate histogram for generated image\n",
        "        generated_hist = compute_color_histogram(images[0], bins=8)\n",
        "        \n",
        "        # Calculate EMD distance using top-k values\n",
        "        emd_distance = calculate_emd_distance_topk(original_histogram, generated_hist, top_k=top_k, blur=0.01)\n",
        "        \n",
        "        attempts_made += 1\n",
        "        \n",
        "        print(f\"Attempt {attempt + 1:2d}: EMD = {emd_distance:.4f}\", end=\"\")\n",
        "        \n",
        "        # Check if this is the best result so far\n",
        "        if emd_distance < best_emd:\n",
        "            best_emd = emd_distance\n",
        "            best_images = images\n",
        "            print(\" ‚Üê NEW BEST!\")\n",
        "        else:\n",
        "            print()\n",
        "        \n",
        "        # Check if we've reached the target threshold\n",
        "        if emd_distance <= target_emd_threshold:\n",
        "            print(f\"\\n‚úì Target EMD reached! ({emd_distance:.4f} <= {target_emd_threshold:.3f})\")\n",
        "            break\n",
        "    \n",
        "    # Display results\n",
        "    if best_images:\n",
        "        comparison = degis.display_comparison_grid(\n",
        "            original=pil_img,\n",
        "            control=control_image,\n",
        "            generated=best_images,\n",
        "            cols=3\n",
        "        )\n",
        "        display(comparison)\n",
        "        \n",
        "        print(f\"\\n‚úì Generation complete!\")\n",
        "        print(f\"Best EMD achieved: {best_emd:.4f}\")\n",
        "        print(f\"Attempts made: {attempts_made}\")\n",
        "    \n",
        "    return best_images, best_emd, attempts_made\n",
        "\n",
        "print(\"‚úì IP-Adapter XL EMD-constrained generation function defined (top-k EMD)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Efficiency benchmark loop\n",
        "# =========================\n",
        "import time, csv, os, math\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "LOG_CSV      = Path(\"efficiency_logs.csv\")\n",
        "SUMMARY_CSV  = Path(\"efficiency_summary.csv\")\n",
        "\n",
        "# ---- core timer/logger (fixed columns + optional outer-loop fields) ----\n",
        "def timed_generate(run_name, gen_fn, *, resolution, steps, cfg,\n",
        "                   attn_ip, ip_scale, text_scale, cn_scale=None, precision=\"fp16\"):\n",
        "    # warmup\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "    _ = gen_fn(warmup=True)\n",
        "\n",
        "    # measure\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "    t0 = time.perf_counter()\n",
        "    out = gen_fn(warmup=False)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "        peak = torch.cuda.max_memory_allocated() / (1024**2)  # MB\n",
        "    else:\n",
        "        peak = 0.0\n",
        "    dt_ms = (time.perf_counter() - t0) * 1000.0\n",
        "\n",
        "    # outer loop meta (if gen_fn returned (images, meta))\n",
        "    attempts = \"\"\n",
        "    best_emd = \"\"\n",
        "    if isinstance(out, (tuple, list)) and len(out) >= 2 and isinstance(out[1], dict):\n",
        "        attempts = out[1].get(\"attempts\", \"\")\n",
        "        best_emd = out[1].get(\"best_emd\", \"\")\n",
        "\n",
        "    row = dict(\n",
        "        run=run_name,\n",
        "        res=resolution,\n",
        "        steps=steps,\n",
        "        cfg=cfg,\n",
        "        attn_ip=attn_ip,\n",
        "        ip_scale=ip_scale,\n",
        "        text_scale=text_scale,\n",
        "        cn_scale=(\"\" if cn_scale is None else cn_scale),\n",
        "        latency_ms=round(dt_ms, 1),\n",
        "        peak_vram_mb=int(peak),\n",
        "        precision=precision,\n",
        "        attempts=attempts,\n",
        "        best_emd=best_emd,\n",
        "    )\n",
        "\n",
        "    new = not LOG_CSV.exists()\n",
        "    with LOG_CSV.open(\"a\", newline=\"\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=row.keys())\n",
        "        if new: w.writeheader()\n",
        "        w.writerow(row)\n",
        "    return row\n",
        "\n",
        "# ---- gen_fn builders using your helpers -----------------------------------\n",
        "# NOTE: these call your notebook helpers you showed earlier.\n",
        "\n",
        "def build_gen_fn_standard(*, colour_index, layout_index, prompt,\n",
        "                          steps, cfg, attn_ip, ip_scale, text_scale,\n",
        "                          cn_scale=0.0, ip_uncond=0.0, zero_ip=True):\n",
        "    \"\"\"\n",
        "    Non-EMD generation (palette and/or edges depending on scales),\n",
        "    wraps your `generate_from_dataset_id_xl(...)` call if available.\n",
        "    Fallback: call the `generator.generate(...)` directly if you prefer.\n",
        "    \"\"\"\n",
        "    def gen_fn(warmup=False):\n",
        "        s = 5 if warmup else steps\n",
        "        # If you have a plain version without EMD:\n",
        "        return generate_from_dataset_id_xl(\n",
        "            colour_index=colour_index,\n",
        "            layout_index=layout_index,\n",
        "            prompt=prompt,\n",
        "            guidance_scale=cfg,\n",
        "            steps=s,\n",
        "            controlnet_conditioning_scale=cn_scale,\n",
        "            num_samples=1,\n",
        "            attn_ip_scale=attn_ip,\n",
        "            text_token_scale=text_scale,\n",
        "            ip_token_scale=ip_scale,\n",
        "            ip_uncond_scale=ip_uncond,\n",
        "            zero_ip_in_uncond=zero_ip,\n",
        "        )\n",
        "        # If you *don't* have generate_from_dataset_id_xl, you can switch to your lower-level:\n",
        "        # imgs = generator.generate(\n",
        "        #     color_embedding=degis.get_color_embedding(color_head, torch.as_tensor(embeddings[colour_index], dtype=torch.float32, device=device).unsqueeze(0)),\n",
        "        #     control_image=degis.create_edge_control_image(edge_maps[layout_index], size=resolution) if cn_scale>0 else None,\n",
        "        #     prompt=prompt, negative_prompt=\"monochrome, lowres, bad anatomy, worst quality\",\n",
        "        #     num_samples=1, guidance_scale=cfg, num_inference_steps=s,\n",
        "        #     attn_ip_scale=attn_ip, text_token_scale=text_scale, ip_token_scale=ip_scale,\n",
        "        #     ip_uncond_scale=ip_uncond, zero_ip_in_uncond=zero_ip,\n",
        "        #     controlnet_conditioning_scale=cn_scale,\n",
        "        # )\n",
        "        # return imgs\n",
        "    return gen_fn\n",
        "\n",
        "def build_gen_fn_outer(*, colour_index, layout_index, prompt,\n",
        "                       steps, cfg, attn_ip, ip_scale, text_scale,\n",
        "                       cn_scale=0.9, tau=0.02, top_k=20, max_attempts=20,\n",
        "                       ip_uncond=0.0, zero_ip=True):\n",
        "    \"\"\"\n",
        "    EMD-constrained variant using your `generate_from_dataset_id_xl_with_emd(...)`.\n",
        "    We return (images, meta) where meta has attempts & best_emd for the logger.\n",
        "    \"\"\"\n",
        "    def gen_fn(warmup=False):\n",
        "        s = 5 if warmup else steps\n",
        "        imgs, best_emd, attempts = generate_from_dataset_id_xl_with_emd(\n",
        "            colour_index=colour_index,\n",
        "            layout_index=layout_index,\n",
        "            prompt=prompt,\n",
        "            target_emd_threshold=tau,\n",
        "            max_attempts=max_attempts,\n",
        "            top_k=top_k,\n",
        "            guidance_scale=cfg,\n",
        "            steps=s,\n",
        "            controlnet_conditioning_scale=cn_scale,\n",
        "            num_samples=1,\n",
        "            attn_ip_scale=attn_ip,\n",
        "            text_token_scale=text_scale,\n",
        "            ip_token_scale=ip_scale,\n",
        "            ip_uncond_scale=ip_uncond,\n",
        "            zero_ip_in_uncond=zero_ip,\n",
        "        )\n",
        "        return imgs, {\"attempts\": attempts, \"best_emd\": round(float(best_emd), 4)}\n",
        "    return gen_fn\n",
        "\n",
        "# ---- experiment grid -------------------------------------------------------\n",
        "PROMPTS = [\n",
        "    \"a dog on the hoodie, artistic style, professional photography, online store product image\",\n",
        "    \"a modern teapot studio photo with soft rim lighting, 3/4 angle\",\n",
        "    \"a sneaker product shot on seamless background, top-down view\",\n",
        "    \"a cozy living room with a navy couch and brass lamp, interior design\",\n",
        "    \"a minimalist poster of a mountain at sunrise, graphic design\",\n",
        "]\n",
        "\n",
        "# Use the same colour/layout indices for fairness (you can change these)\n",
        "COLOUR_INDEX = 1008\n",
        "LAYOUT_INDEX = 33\n",
        "\n",
        "# Fixed gauges (same across runs)\n",
        "GAUGES = dict(attn_ip=0.6, ip_scale=0.4, text_scale=1.1)\n",
        "\n",
        "# Settings we want in Table \\ref{tab:eff-stack}\n",
        "STACK_SETTINGS = [\n",
        "    dict(name=\"text_only\",           cn_scale=0.0, attn_ip=0.0, ip_scale=0.0, text_scale=1.0),\n",
        "    dict(name=\"+palette\",            cn_scale=0.0, **GAUGES),\n",
        "    dict(name=\"+edges\",              cn_scale=0.9, attn_ip=0.0, ip_scale=0.0, text_scale=1.0),\n",
        "    dict(name=\"+palette+edges\",      cn_scale=0.9, **GAUGES),\n",
        "    dict(name=\"+palette+edges+outer\", cn_scale=0.9, **GAUGES, outer=True, tau=0.02, top_k=20, max_attempts=20),\n",
        "]\n",
        "\n",
        "# Base preset for 512px table\n",
        "RESOLUTION = 512\n",
        "STEPS      = 100\n",
        "CFG        = 7.5\n",
        "\n",
        "# Optional resolution scaling row for the best setting\n",
        "SCALE_1024 = dict(resolution=1024, steps=50, cfg=7.0)\n",
        "\n",
        "# ---- run the suite ---------------------------------------------------------\n",
        "def run_efficiency_suite():\n",
        "    # Clear old logs if you want a clean run:\n",
        "    # LOG_CSV.unlink(missing_ok=True); SUMMARY_CSV.unlink(missing_ok=True)\n",
        "\n",
        "    for p_idx, prompt in enumerate(PROMPTS):\n",
        "        for s in STACK_SETTINGS:\n",
        "            label = s[\"name\"]\n",
        "            if s.get(\"outer\", False):\n",
        "                gen_fn = build_gen_fn_outer(\n",
        "                    colour_index=COLOUR_INDEX, layout_index=LAYOUT_INDEX, prompt=prompt,\n",
        "                    steps=STEPS, cfg=CFG,\n",
        "                    attn_ip=s[\"attn_ip\"], ip_scale=s[\"ip_scale\"], text_scale=s[\"text_scale\"],\n",
        "                    cn_scale=s[\"cn_scale\"], tau=s[\"tau\"], top_k=s[\"top_k\"], max_attempts=s[\"max_attempts\"]\n",
        "                )\n",
        "            else:\n",
        "                gen_fn = build_gen_fn_standard(\n",
        "                    colour_index=COLOUR_INDEX, layout_index=LAYOUT_INDEX, prompt=prompt,\n",
        "                    steps=STEPS, cfg=CFG,\n",
        "                    attn_ip=s[\"attn_ip\"], ip_scale=s[\"ip_scale\"], text_scale=s[\"text_scale\"],\n",
        "                    cn_scale=s[\"cn_scale\"]\n",
        "                )\n",
        "\n",
        "            run_name = f\"sdxl_{RESOLUTION}_{label}\"\n",
        "            timed_generate(run_name, gen_fn,\n",
        "                           resolution=RESOLUTION, steps=STEPS, cfg=CFG,\n",
        "                           attn_ip=s[\"attn_ip\"], ip_scale=s[\"ip_scale\"], text_scale=s[\"text_scale\"],\n",
        "                           cn_scale=s[\"cn_scale\"], precision=\"fp16\")\n",
        "\n",
        "    # Optional 1024 scaling row for the best setting (+palette+edges)\n",
        "    best = next(x for x in STACK_SETTINGS if x[\"name\"] == \"+palette+edges\")\n",
        "    for p_idx, prompt in enumerate(PROMPTS):\n",
        "        gen_fn_1024 = build_gen_fn_standard(\n",
        "            colour_index=COLOUR_INDEX, layout_index=LAYOUT_INDEX, prompt=prompt,\n",
        "            steps=SCALE_1024[\"steps\"], cfg=SCALE_1024[\"cfg\"],\n",
        "            attn_ip=best[\"attn_ip\"], ip_scale=best[\"ip_scale\"], text_scale=best[\"text_scale\"],\n",
        "            cn_scale=best[\"cn_scale\"]\n",
        "        )\n",
        "        run_name = f\"sdxl_{SCALE_1024['resolution']}_+palette+edges\"\n",
        "        timed_generate(run_name, gen_fn_1024,\n",
        "                       resolution=SCALE_1024[\"resolution\"], steps=SCALE_1024[\"steps\"], cfg=SCALE_1024[\"cfg\"],\n",
        "                       attn_ip=best[\"attn_ip\"], ip_scale=best[\"ip_scale\"], text_scale=best[\"text_scale\"],\n",
        "                       cn_scale=best[\"cn_scale\"], precision=\"fp16\")\n",
        "\n",
        "    print(f\"‚úì Wrote raw logs to {LOG_CSV.resolve()}\")\n",
        "    summarize_efficiency(LOG_CSV, SUMMARY_CSV)\n",
        "    print(f\"‚úì Wrote summary to {SUMMARY_CSV.resolve()}\")\n",
        "\n",
        "# ---- summarizer to produce the thesis table numbers ------------------------\n",
        "def summarize_efficiency(log_csv: Path, out_csv: Path):\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(log_csv)\n",
        "    # derive setting from 'run' name\n",
        "    df[\"setting\"] = df[\"run\"].str.extract(r\"sdxl_\\d+_(.*)\")\n",
        "    # throughput (img/s)\n",
        "    df[\"throughput\"] = 1000.0 / df[\"latency_ms\"]\n",
        "\n",
        "    # group by setting & res & steps/cfg\n",
        "    grp_cols = [\"setting\", \"res\", \"steps\", \"cfg\"]\n",
        "    agg = df.groupby(grp_cols).agg(\n",
        "        latency_ms_mean=(\"latency_ms\", \"mean\"),\n",
        "        latency_ms_std=(\"latency_ms\", \"std\"),\n",
        "        peak_vram_mb_mean=(\"peak_vram_mb\", \"mean\"),\n",
        "        peak_vram_mb_std=(\"peak_vram_mb\", \"std\"),\n",
        "        throughput_mean=(\"throughput\", \"mean\"),\n",
        "        attempts_median=(\"attempts\", \"median\"),\n",
        "        best_emd_median=(\"best_emd\", \"median\"),\n",
        "        n=(\"run\", \"count\"),\n",
        "    ).reset_index()\n",
        "\n",
        "    # nice rounding\n",
        "    for col in [\"latency_ms_mean\",\"latency_ms_std\",\"peak_vram_mb_mean\",\"peak_vram_mb_std\",\"throughput_mean\",\"best_emd_median\"]:\n",
        "        if col in agg: agg[col] = agg[col].astype(float).round(1)\n",
        "    if \"attempts_median\" in agg: agg[\"attempts_median\"] = pd.to_numeric(agg[\"attempts_median\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "    agg.to_csv(out_csv, index=False)\n",
        "    print(agg)\n",
        "\n",
        "# ---- run it ---------------------------------------------------------------\n",
        "run_efficiency_suite()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_emd_distance_topk(\n",
        "    hist1: np.ndarray, \n",
        "    hist2: np.ndarray, \n",
        "    top_k: int = 20, \n",
        "    blur: float = 0.01\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Calculate Earth Mover's Distance between top-k histogram values using Sinkhorn algorithm.\n",
        "    Supports histograms of variable lengths (e.g., 512 for RGB or 514 for LAB).\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure both histograms are same length\n",
        "    if hist1.shape[0] != hist2.shape[0]:\n",
        "        raise ValueError(f\"Histogram size mismatch: {hist1.shape[0]} vs {hist2.shape[0]}\")\n",
        "\n",
        "    # Get top-k indices for both histograms\n",
        "    k = min(top_k, hist1.shape[0])  # prevent out-of-bounds\n",
        "    top_indices_1 = np.argsort(hist1)[-k:]\n",
        "    top_indices_2 = np.argsort(hist2)[-k:]\n",
        "\n",
        "    # Get union of indices\n",
        "    unique_indices = np.union1d(top_indices_1, top_indices_2)\n",
        "\n",
        "    # Extract top values\n",
        "    h1_topk = hist1[unique_indices]\n",
        "    h2_topk = hist2[unique_indices]\n",
        "\n",
        "    # Normalize to sum to 1\n",
        "    h1_topk = h1_topk / (h1_topk.sum() + 1e-8)\n",
        "    h2_topk = h2_topk / (h2_topk.sum() + 1e-8)\n",
        "\n",
        "    # Convert to tensors\n",
        "    h1 = torch.tensor(h1_topk, dtype=torch.float32).unsqueeze(0)\n",
        "    h2 = torch.tensor(h2_topk, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    # Calculate Sinkhorn EMD\n",
        "    loss = geomloss.SamplesLoss(\"sinkhorn\", p=2, blur=blur, backend=\"tensorized\")\n",
        "    emd = loss(h1, h2).item()\n",
        "\n",
        "    return emd\n",
        "\n",
        "\n",
        "def generate_from_dataset_id_xl_with_emd(\n",
        "    colour_index: int,\n",
        "    layout_index: int,\n",
        "    prompt: str = \"a cat playing with a ball\",\n",
        "    target_emd_threshold: float = 0.1,\n",
        "    max_attempts: int = 20,\n",
        "    top_k: int = 20,  # New parameter for top-k EMD\n",
        "    guidance_scale: float = 6.5,\n",
        "    steps: int = 40,\n",
        "    controlnet_conditioning_scale: float = 0.8,\n",
        "    num_samples: int = 1,\n",
        "    attn_ip_scale: float = 0.8,\n",
        "    text_token_scale: float = 1.0,\n",
        "    ip_token_scale: float = None,\n",
        "    ip_uncond_scale: float = 0.0,\n",
        "    zero_ip_in_uncond: bool = True,\n",
        "):\n",
        "    import torch, gc\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    \"\"\"Generate images using IP-Adapter XL with EMD constraint on top-k histogram values.\"\"\"\n",
        "\n",
        "    # Get original image for display\n",
        "    img_t, _ = colour_dataset[colour_index]\n",
        "    pil_img = transforms.ToPILImage()(img_t)\n",
        "\n",
        "    # Get CLIP embedding and compute color embedding\n",
        "    z_clip = torch.as_tensor(embeddings[colour_index], dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    color_embedding = degis.get_color_embedding(color_head, z_clip)\n",
        "\n",
        "    # Get original histogram for EMD comparison\n",
        "    original_histogram = histograms[colour_index]\n",
        "\n",
        "    # Auto-detect histogram type (RGB 512 vs LAB 514)\n",
        "    if original_histogram.shape[0] == 512:\n",
        "        color_space = \"rgb\"\n",
        "    elif original_histogram.shape[0] == 514:\n",
        "        color_space = \"lab\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported histogram length: {original_histogram.shape[0]}\")\n",
        "\n",
        "    # Create control image from edge data\n",
        "    control_image = degis.create_edge_control_image(edge_maps[layout_index], size=512)\n",
        "\n",
        "    # EMD-constrained generation\n",
        "    best_images = None\n",
        "    best_emd = float(\"inf\")\n",
        "    attempts_made = 0\n",
        "\n",
        "    print(f\"Generating with EMD constraint (target: {target_emd_threshold:.3f})\")\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(f\"Max attempts: {max_attempts}\")\n",
        "    print(f\"EMD calculation: top-{top_k} histogram values, color_space={color_space}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"{'Attempt':<8} {'EMD':<10} {'attn_ip_scale':<15} {'ip_token_scale':<15} {'guidance_scale':<15}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for attempt in range(max_attempts):\n",
        "        # Generate images with IP-Adapter XL\n",
        "        images = generator.generate(\n",
        "            color_embedding=color_embedding,\n",
        "            control_image=control_image,\n",
        "            prompt=prompt,\n",
        "            negative_prompt=(\n",
        "                \"monochrome, lowres, bad anatomy, worst quality, low quality, blurry, \"\n",
        "                \"sketch, cartoon, drawing, anime:1.4, comic, illustration, posterized, \"\n",
        "                \"mosaic, stained glass, abstract, surreal, psychedelic, trippy, texture artifact, \"\n",
        "                \"embroidery, knitted, painting, oversaturated, unrealistic, bad shading\"\n",
        "            ),\n",
        "            num_samples=num_samples,\n",
        "            guidance_scale=guidance_scale,\n",
        "            num_inference_steps=steps,\n",
        "            controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
        "            attn_ip_scale=attn_ip_scale,\n",
        "            text_token_scale=text_token_scale,\n",
        "            ip_token_scale=ip_token_scale,\n",
        "            ip_uncond_scale=ip_uncond_scale,\n",
        "            zero_ip_in_uncond=zero_ip_in_uncond,\n",
        "        )\n",
        "\n",
        "        # Calculate histogram for generated image (use detected color_space)\n",
        "        generated_hist = compute_lab_histogram(images[0], bins=8)\n",
        "        emd_distance = calculate_emd_distance_topk(\n",
        "            original_histogram, generated_hist, top_k=top_k, blur=0.01\n",
        "        )\n",
        "\n",
        "        attempts_made += 1\n",
        "\n",
        "        # Structured logging\n",
        "        print(f\"{attempt+1:<8} {emd_distance:<10.4f} {attn_ip_scale:<15.3f} {ip_token_scale or 0:<15.3f} {guidance_scale:<15.3f}\", end=\"\")\n",
        "\n",
        "        # Check if this is the best result so far\n",
        "        if emd_distance < best_emd:\n",
        "            best_emd = emd_distance\n",
        "            best_images = images\n",
        "            print(\"  ‚Üê NEW BEST!\")\n",
        "        else:\n",
        "            print()\n",
        "\n",
        "        # Check if we've reached the target threshold\n",
        "        if emd_distance <= target_emd_threshold:\n",
        "            print(f\"\\n‚úì Target EMD reached! ({emd_distance:.4f} <= {target_emd_threshold:.3f})\")\n",
        "            break\n",
        "\n",
        "    # Display results\n",
        "    if best_images:\n",
        "        comparison = degis.display_comparison_grid(\n",
        "            original=pil_img, control=control_image, generated=best_images, cols=3\n",
        "        )\n",
        "        display(comparison)\n",
        "\n",
        "        print(f\"\\n‚úì Generation complete!\")\n",
        "        print(f\"Best EMD achieved: {best_emd:.4f}\")\n",
        "        print(f\"Attempts made: {attempts_made}\")\n",
        "\n",
        "    return best_images, best_emd, attempts_made\n",
        "\n",
        "\n",
        "print(\"‚úì IP-Adapter XL EMD-constrained generation function defined (with structured logging)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_from_dataset_id_xl_with_emd(\n",
        "    colour_index=100002,\n",
        "    layout_index=30,\n",
        "    prompt = \"a car, advertisement style, professional photography\",\n",
        "    target_emd_threshold=0.02,\n",
        "    max_attempts=20,\n",
        "    guidance_scale=15,\n",
        "    steps=50,\n",
        "    controlnet_conditioning_scale=0.5,\n",
        "    num_samples=1,\n",
        "    attn_ip_scale=0.6,\n",
        "    text_token_scale=1.1,\n",
        "    ip_token_scale=0.4,\n",
        "    ip_uncond_scale=0.0,\n",
        "    zero_ip_in_uncond=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: Dog on hoodie (artistic style)\n",
        "images2 = generate_from_dataset_id_xl_with_emd(\n",
        "    colour_index=1000,\n",
        "    layout_index=33,\n",
        "    prompt=\"a bird on the hoodie, artistic style, professional photography, online store product image\",\n",
        "    target_emd_threshold=0.02,\n",
        "    max_attempts=10,\n",
        "    guidance_scale=7.5,\n",
        "    steps=50,\n",
        "    controlnet_conditioning_scale=0.5,\n",
        "    num_samples=1,\n",
        "    attn_ip_scale=0.6,\n",
        "    text_token_scale=1.1,\n",
        "    ip_token_scale=0.4,\n",
        "    ip_uncond_scale=0.0,\n",
        "    zero_ip_in_uncond=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==== Aligned GT vs Pred top-20 + IMAGE (first 10) ====\n",
        "import os, numpy as np, torch, matplotlib.pyplot as plt, pandas as pd\n",
        "from skimage.color import lab2rgb\n",
        "BINS      = 8\n",
        "TOP_K     = 20\n",
        "SPACE = \"lab\"\n",
        "hist = histograms\n",
        "emb = embeddings\n",
        "HIST_KIND = \"lab514\"   # \"rgb512\" | \"lab514\" | \"hcl514\"\n",
        "sinkhorn = geomloss.SamplesLoss(\"sinkhorn\", p=2, blur=0.05, backend=\"tensorized\")\n",
        "def _top_palette(vec, bins=BINS, top_k=TOP_K, space=SPACE, c_max=150.0):\n",
        "    v = vec.detach().cpu().numpy() if isinstance(vec, torch.Tensor) else np.asarray(vec)\n",
        "    core = v[:bins**3]  # ignore the last 2 BW slots for palette picking\n",
        "    idxs = np.argsort(core)[-top_k:][::-1]\n",
        "    cols = []\n",
        "    if space == \"rgb\":\n",
        "        for flat in idxs:\n",
        "            ri = flat // (bins*bins); gi = (flat // bins) % bins; bi = flat % bins\n",
        "            cols.append(((ri+0.5)/bins, (gi+0.5)/bins, (bi+0.5)/bins))\n",
        "    elif space == \"lab\":\n",
        "        for flat in idxs:\n",
        "            Li = flat // (bins*bins); ai = (flat // bins) % bins; bi = flat % bins\n",
        "            L = (Li+0.5)/bins*100.0\n",
        "            a = (ai+0.5)/bins*255.0 - 128.0\n",
        "            b = (bi+0.5)/bins*255.0 - 128.0\n",
        "            cols.append(tuple(lab2rgb(np.array([[[L,a,b]]]))[0,0]))\n",
        "    elif space == \"hcl\":\n",
        "        for flat in idxs:\n",
        "            Li = flat // (bins*bins); Ci = (flat // bins) % bins; Hi = flat % bins\n",
        "            L = (Li+0.5)/bins*100.0\n",
        "            C = (Ci+0.5)/bins*c_max\n",
        "            H = (Hi+0.5)/bins*360.0\n",
        "            a = C*np.cos(np.deg2rad(H)); b = C*np.sin(np.deg2rad(H))\n",
        "            cols.append(tuple(lab2rgb(np.array([[[L,a,b]]]))[0,0]))\n",
        "    else:\n",
        "        raise ValueError(\"space must be 'rgb' | 'lab' | 'hcl'\")\n",
        "    return cols, core[idxs]\n",
        "\n",
        "def _plot_palette(ax, colors, values, title):\n",
        "    for i, (c, v) in enumerate(zip(colors, values)):\n",
        "        ax.add_patch(plt.Rectangle((i, 0), 1, 1, color=c))\n",
        "        ax.text(i+0.5, -0.08, f\"{v:.3f}\", ha=\"center\", va=\"top\", fontsize=7)\n",
        "    ax.set_xlim(0, len(colors)); ax.set_ylim(0,1); ax.axis(\"off\")\n",
        "    ax.set_title(title, fontsize=12)\n",
        "\n",
        "def show_aligned(i, dataset):\n",
        "    # image from the SAME dataset (guarantees correct ordering)\n",
        "    img_t, _ = dataset[i]                    # [3,224,224] float [0,1]\n",
        "    img_np   = img_t.permute(1,2,0).numpy()  # HWC\n",
        "\n",
        "    # GT and Pred from aligned arrays / model\n",
        "    h_gt = torch.from_numpy(hist[i]).to(device)\n",
        "    z    = torch.from_numpy(emb[i]).to(device).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _, p, _ = color_head(z)\n",
        "        p = p.squeeze(0)\n",
        "        p = p / (p.sum() + 1e-8)\n",
        "        g = h_gt / (h_gt.sum() + 1e-8)\n",
        "        l1  = torch.sum(torch.abs(p-g)).item()\n",
        "        cos = torch.nn.functional.cosine_similarity(p, g, dim=0).item()\n",
        "        emd = sinkhorn(p.unsqueeze(0), g.unsqueeze(0)).item() if sinkhorn is not None else None\n",
        "\n",
        "    gt_cols, gt_vals = _top_palette(g)\n",
        "    pr_cols, pr_vals = _top_palette(p)\n",
        "\n",
        "    # draw\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 5), gridspec_kw={\"height_ratios\":[2,1]})\n",
        "    axes[0,0].imshow(img_np); axes[0,0].axis(\"off\")\n",
        "    basename = os.path.basename(str(dataset.df.iloc[i][\"file_path\"]))\n",
        "    axes[0,0].set_title(f\"idx={i}  ({basename})\")\n",
        "\n",
        "    axes[0,1].axis(\"off\")\n",
        "    txt = f\"Histogram kind: {HIST_KIND}\\nL1 = {l1:.4f}\\nCosine = {cos:.4f}\"\n",
        "    if emd is not None: txt += f\"\\nEMD = {emd:.4f}\"\n",
        "    axes[0,1].text(0.02, 0.85, txt, fontsize=12, va=\"top\")\n",
        "\n",
        "    _plot_palette(axes[1,0], gt_cols, gt_vals, f\"GT top-{TOP_K}\")\n",
        "    _plot_palette(axes[1,1], pr_cols, pr_vals, f\"Pred top-{TOP_K}\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "# for i in range(1000, 1010):\n",
        "#     show_aligned(i, colour_dataset)\n",
        "for i in range(1000, 1010):\n",
        "    show_aligned(i, colour_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DEGIS Environment",
      "language": "python",
      "name": "degis"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
