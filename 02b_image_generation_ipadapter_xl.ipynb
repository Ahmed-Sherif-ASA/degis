{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Generation with IP-Adapter XL (SDXL)\n",
        "\n",
        "This notebook demonstrates how to use the DEGIS package to:\n",
        "1. Load trained color head models\n",
        "2. Set up IP-Adapter XL with ControlNet for high-quality image generation\n",
        "3. Generate images using color and layout control with SDXL\n",
        "\n",
        "Based on the ablation notebook but using IP-Adapter XL for higher quality results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install IP-Adapter and dependencies\n",
        "%pip uninstall -y ip-adapter diffusers\n",
        "%pip install --no-cache-dir git+https://github.com/Ahmed-Sherif-ASA/IP-Adapter@main\n",
        "%pip install diffusers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from IPython.display import display\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Import the DEGIS package\n",
        "import degis\n",
        "from degis.data.dataset import UnifiedImageDataset\n",
        "from degis.config import CSV_PATH, HF_XL_EMBEDDINGS_TARGET_PATH, COLOR_HIST_PATH_HCL_514, EDGE_MAPS_PATH\n",
        "\n",
        "# Import IP-Adapter XL\n",
        "import ip_adapter\n",
        "from ip_adapter import IPAdapterXL\n",
        "from diffusers import ControlNetModel, StableDiffusionXLControlNetPipeline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Data and Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "colour_dataset = UnifiedImageDataset(\n",
        "    df.rename(columns={\"local_path\": \"file_path\"}),\n",
        "    mode=\"file_df\",\n",
        "    size=(224, 224),\n",
        "    subset_ratio=1.0\n",
        ")\n",
        "\n",
        "# Load precomputed data\n",
        "embeddings = np.load(HF_XL_EMBEDDINGS_TARGET_PATH, mmap_mode=\"r\").astype(np.float32, copy=False)\n",
        "histograms = np.load(COLOR_HIST_PATH_HCL_514, mmap_mode=\"r\").astype(np.float32, copy=False)\n",
        "edge_maps = np.load(EDGE_MAPS_PATH, mmap_mode=\"r\")\n",
        "\n",
        "print(f\"Loaded embeddings: {embeddings.shape}\")\n",
        "print(f\"Loaded histograms: {histograms.shape}\")\n",
        "print(f\"Loaded edge maps: {edge_maps.shape}\")\n",
        "\n",
        "# Find the latest trained model\n",
        "run_dirs = glob.glob(\"runs/*\")\n",
        "if run_dirs:\n",
        "    latest_run = max(run_dirs, key=os.path.getctime)\n",
        "    checkpoint_path = os.path.join(latest_run, \"best_color_head_tmp.pth\")\n",
        "    print(f\"Using checkpoint: {checkpoint_path}\")\n",
        "else:\n",
        "    # Fallback to a default path\n",
        "    checkpoint_path = \"best_color_head.pth\"\n",
        "    print(f\"Using default checkpoint: {checkpoint_path}\")\n",
        "\n",
        "# Load trained color head\n",
        "color_head = degis.load_trained_color_head(\n",
        "    checkpoint_path=checkpoint_path,\n",
        "    clip_dim=embeddings.shape[1],\n",
        "    hist_dim=histograms.shape[1],\n",
        "    device=device\n",
        ")\n",
        "print(\"✓ Color head loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup IP-Adapter XL Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup cache directory\n",
        "HF_CACHE = \"/data/hf-cache\" if os.path.exists(\"/data\") else \"./hf-cache\"\n",
        "os.makedirs(HF_CACHE, exist_ok=True)\n",
        "\n",
        "os.environ[\"HF_HOME\"] = HF_CACHE\n",
        "os.environ[\"HUGGINGFACE_HUB_CACHE\"] = os.path.join(HF_CACHE, \"hub\")\n",
        "os.environ[\"TRANSFORMERS_CACHE\"] = os.path.join(HF_CACHE, \"transformers\")\n",
        "os.environ[\"DIFFUSERS_CACHE\"] = os.path.join(HF_CACHE, \"diffusers\")\n",
        "os.environ[\"TORCH_HOME\"] = os.path.join(HF_CACHE, \"torch\")\n",
        "\n",
        "print(f\"Using cache directory: {HF_CACHE}\")\n",
        "\n",
        "# Create IP-Adapter XL generator\n",
        "generator = degis.IPAdapterXLGenerator(device=device)\n",
        "\n",
        "# Setup the pipeline\n",
        "generator.setup_pipeline(\n",
        "    model_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    controlnet_id=\"diffusers/controlnet-canny-sdxl-1.0\",\n",
        "    ip_ckpt=\"/data/thesis/models/ip-adapter_sdxl.bin\",  # Update path as needed\n",
        "    image_encoder_path=\"laion/CLIP-ViT-bigG-14-laion2B-39B-b160k\",\n",
        "    cache_dir=HF_CACHE,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "print(\"✓ IP-Adapter XL pipeline setup complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Image Generation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_from_dataset_id_xl(\n",
        "    colour_index: int,\n",
        "    layout_index: int,\n",
        "    prompt: str = \"a cat playing with a ball\",\n",
        "    guidance_scale: float = 6.5,\n",
        "    steps: int = 40,\n",
        "    controlnet_conditioning_scale: float = 0.8,\n",
        "    num_samples: int = 1,\n",
        "    attn_ip_scale: float = 0.8,\n",
        "    text_token_scale: float = 1.0,\n",
        "    ip_token_scale: float = None,\n",
        "    ip_uncond_scale: float = 0.0,\n",
        "    zero_ip_in_uncond: bool = True,\n",
        "):\n",
        "    \"\"\"Generate images using IP-Adapter XL with advanced controls.\"\"\"\n",
        "    \n",
        "    # Get original image for display\n",
        "    img_t, _ = colour_dataset[colour_index]\n",
        "    pil_img = transforms.ToPILImage()(img_t)\n",
        "    \n",
        "    # Get CLIP embedding and compute color embedding\n",
        "    z_clip = torch.as_tensor(embeddings[colour_index], dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    color_embedding = degis.get_color_embedding(color_head, z_clip)\n",
        "    \n",
        "    # Create control image from edge data\n",
        "    control_image = degis.create_edge_control_image(edge_maps[layout_index], size=512)\n",
        "    \n",
        "    # Generate images with IP-Adapter XL\n",
        "    images = generator.generate(\n",
        "        color_embedding=color_embedding,\n",
        "        control_image=control_image,\n",
        "        prompt=prompt,\n",
        "        negative_prompt=(\n",
        "            \"monochrome, lowres, bad anatomy, worst quality, low quality, blurry, \"\n",
        "            \"sketch, cartoon, drawing, anime:1.4, comic, illustration, posterized, \"\n",
        "            \"mosaic, stained glass, abstract, surreal, psychedelic, trippy, texture artifact, \"\n",
        "            \"embroidery, knitted, painting, oversaturated, unrealistic, bad shading\"\n",
        "        ),\n",
        "        num_samples=num_samples,\n",
        "        guidance_scale=guidance_scale,\n",
        "        num_inference_steps=steps,\n",
        "        controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
        "        # IP-Adapter XL specific parameters\n",
        "        attn_ip_scale=attn_ip_scale,\n",
        "        text_token_scale=text_token_scale,\n",
        "        ip_token_scale=ip_token_scale,\n",
        "        ip_uncond_scale=ip_uncond_scale,\n",
        "        zero_ip_in_uncond=zero_ip_in_uncond,\n",
        "    )\n",
        "    \n",
        "    # Display results\n",
        "    comparison = degis.display_comparison_grid(\n",
        "        original=pil_img,\n",
        "        control=control_image,\n",
        "        generated=images,\n",
        "        cols=3\n",
        "    )\n",
        "    display(comparison)\n",
        "    \n",
        "    return images\n",
        "\n",
        "print(\"✓ IP-Adapter XL generation function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Generate High-Quality Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate high-quality images with IP-Adapter XL\n",
        "print(\"Generating images with IP-Adapter XL (SDXL)...\")\n",
        "\n",
        "# Example 1: Cat with ball (high quality)\n",
        "images1 = generate_from_dataset_id_xl(\n",
        "    colour_index=1000,\n",
        "    layout_index=33,\n",
        "    prompt=\"a cat playing with a ball, high quality, detailed\",\n",
        "    guidance_scale=6.5,\n",
        "    steps=40,\n",
        "    controlnet_conditioning_scale=0.8,\n",
        "    num_samples=1,\n",
        "    attn_ip_scale=0.8,\n",
        "    text_token_scale=1.0,\n",
        "    ip_token_scale=0.5,\n",
        "    ip_uncond_scale=0.0,\n",
        "    zero_ip_in_uncond=True,\n",
        ")\n",
        "\n",
        "# Example 2: Dog on hoodie (artistic style)\n",
        "images2 = generate_from_dataset_id_xl(\n",
        "    colour_index=1008,\n",
        "    layout_index=33,\n",
        "    prompt=\"a dog on the hoodie, artistic style, professional photography\",\n",
        "    guidance_scale=7.5,\n",
        "    steps=50,\n",
        "    controlnet_conditioning_scale=0.9,\n",
        "    num_samples=1,\n",
        "    attn_ip_scale=0.6,\n",
        "    text_token_scale=1.1,\n",
        "    ip_token_scale=0.4,\n",
        "    ip_uncond_scale=0.0,\n",
        "    zero_ip_in_uncond=True,\n",
        ")\n",
        "\n",
        "# Example 3: Creative composition\n",
        "images3 = generate_from_dataset_id_xl(\n",
        "    colour_index=1003,\n",
        "    layout_index=33,\n",
        "    prompt=\"A cat on the hoodie, digital art, vibrant colors, masterpiece\",\n",
        "    guidance_scale=8.0,\n",
        "    steps=60,\n",
        "    controlnet_conditioning_scale=0.7,\n",
        "    num_samples=1,\n",
        "    attn_ip_scale=0.7,\n",
        "    text_token_scale=1.2,\n",
        "    ip_token_scale=0.6,\n",
        "    ip_uncond_scale=0.0,\n",
        "    zero_ip_in_uncond=True,\n",
        ")\n",
        "\n",
        "print(\"✓ High-quality image generation complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
